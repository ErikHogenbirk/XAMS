{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hax\n",
    "from hax import cuts\n",
    "import pickle\n",
    "from gain_extrapolator_reduced import get_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class XAMSAnalysis():\n",
    "    '''\n",
    "    This holds the data and functions to perform basic analysis on the XAMS data.\n",
    "    Functions here are:\n",
    "    - ``load`` to load the data and all relevant minitrees\n",
    "    - ``cut_*`` to apply a cut (and give ``plot=True`` to see what it cuts)\n",
    "    - ``cuts_*`` for quick application of multiple cuts\n",
    "    - ``plot_*`` for standard plots.\n",
    "    - ``corr_*`` for corrections\n",
    "    '''\n",
    "    __version__ = '0.0.0'\n",
    "    # Holds dataframe containing all data\n",
    "    d = None\n",
    "    # This will list all basic cuts\n",
    "    cut_list = []\n",
    "    \n",
    "    ################################################# BASICS\n",
    "    \n",
    "    def __init__(self, filenames, processed_data_path, minitree_path, include_NaI = False):\n",
    "        self.filenames = filenames\n",
    "        self.processed_data_path = processed_data_path\n",
    "        self.minitree_path = minitree_path\n",
    "        self.include_NaI = include_NaI\n",
    "        self.cut_list = [\n",
    "            self.cut_interaction_exists,\n",
    "            self.cut_thresholds,\n",
    "            self.cut_low_energy,\n",
    "            self.cut_largest_other_s1,\n",
    "            self.cut_largest_other_s2,\n",
    "            self.cut_saturation,\n",
    "            self.cut_s2_aft,\n",
    "            self.cut_s1_aft,\n",
    "            self.cut_drift_time\n",
    "        ]        \n",
    "        return\n",
    "    \n",
    "    def load(self, verbose=True, **kwargs):\n",
    "        '''\n",
    "        Load the data into datafame using hax.minitrees.load.\n",
    "        Any args will be passed to hax.minitrees.load.\n",
    "        Extra properties computes: \n",
    "        - NaI energy\n",
    "        - Dataset number\n",
    "        - t : time in s since start of run\n",
    "        - Drift time converted to us\n",
    "        - cs1 and cs2 set identical to s1 and s2\n",
    "        '''\n",
    "        hax.init(\n",
    "            # Always use these lines to tell hax that we don't care about Xe1T\n",
    "            experiment='XAMS', \n",
    "            pax_version_policy='loose', use_runs_db = False,\n",
    "            # Here come the useful settings\n",
    "            main_data_paths = [self.processed_data_path],\n",
    "            minitree_paths = [self.minitree_path],       \n",
    "         )\n",
    "        # Load data\n",
    "        if self.include_NaI:\n",
    "            self.d = hax.minitrees.load(self.filenames, ['Fundamentals','Basics', ExtraS1S2Properties, NaIProperties],\n",
    "                                       **kwargs)\n",
    "        else:\n",
    "            self.d = hax.minitrees.load(self.filenames, ['Fundamentals','Basics', ExtraS1S2Properties], **kwargs)\n",
    "        # Recompute drift time to us\n",
    "        self.d['drift_time'] = self.d['drift_time'] * 1e-3\n",
    "        # Set cs1 and cs2 identical to s1\n",
    "        self.d['cs1'] = self.d['s1']\n",
    "        self.d['cs2'] = self.d['s2']\n",
    "        self.d['s2_bot'] = self.d['s2'] * (1 - self.d['s2_area_fraction_top'])\n",
    "        # Compute time since start of run in seconds\n",
    "        self.d['t'] = (self.d['event_time'] - self.d['event_time'].values[0]) * 1e-9\n",
    "        # Calibration of NaI\n",
    "        if self.include_NaI:\n",
    "            self.d['NaI_energy'] = self.d['NaI_area'] * 511 / 1287.8107708648045\n",
    "        \n",
    "        # Re-set the run number by checking for change in event number\n",
    "        dset_change_indices = np.where(np.diff(self.d['event_number']) != 1)[0]\n",
    "        # Number of events in each dataset\n",
    "        dset_lengths = np.diff(np.concatenate([np.array([0]), dset_change_indices + 1, np.array([len(self.d)])]))\n",
    "        if len(dset_lengths) != len(self.filenames):\n",
    "            print('Warning: auto-computing of dataset index failed.')\n",
    "        dset_index_array = np.concatenate([np.ones(dset_length, dtype=int) * i \n",
    "                                           for i, dset_length in enumerate(dset_lengths)])\n",
    "        self.d['run_number'] = dset_index_array\n",
    "        print('Loaded %d (%.1f k) events.' % (len(self.d), len(self.d) * 0.001))\n",
    "        return\n",
    "    \n",
    "    ################################################# ADDING PROPERTIES   \n",
    "    def add_ces(self, g1 = 0.07099636,  g2 = 3.08170177):\n",
    "        # Default g1, g2 values last updated 17/5/2017, post gain change ('triple baseline')\n",
    "        self.d['e_ces'] = 13.7e-3 * (self.d['cs1'] / g1 + self.d['s2_bot'] / g2)\n",
    "        return\n",
    "    \n",
    "    def add_e_s1(self, energy=662, cs1_peak = 1431.9):\n",
    "        self.d['e_s1'] = self.d['cs1'] * energy / cs1_peak\n",
    "        return\n",
    "    \n",
    "    def add_e_s2(self, energy=662, cs2_peak = 86757.7):\n",
    "        '''\n",
    "        Add energy based on single peak in BOTTOM S2 spectrum. Default set for Cs-137\n",
    "        '''\n",
    "        self.d['e_s2'] = self.d['s2_bot'] * energy / cs2_peak\n",
    "        return\n",
    "    \n",
    "    def add_g1g2_props(self, g1 = 0.07099636,  g2 = 3.08170177):\n",
    "        '''\n",
    "        Add properties based on g1 and g2\n",
    "        '''\n",
    "        # Number of gammas\n",
    "        self.d['n_g'] = self.d['cs1'] / g1\n",
    "        self.d['n_e'] = self.d['s2_bot'] / g2\n",
    "        self.d['n_quanta'] = self.d['n_g'] + self.d['n_e']\n",
    "        self.d['f_g'] = self.d['n_g'] / (self.d['n_quanta'])\n",
    "        return\n",
    "        \n",
    "    def add_livetime(self):\n",
    "        '''\n",
    "        Add the total run livetime. Warning: run only on data with high enough event rate and uncut!\n",
    "        '''\n",
    "        time = 0.\n",
    "        for rn in np.unique(self.d['run_number']):\n",
    "            time += (max(self.d[self.d['run_number'] == rn]['t']) - min(self.d[self.d['run_number'] == rn]['t']))\n",
    "        self.livetime = time\n",
    "        return\n",
    "        \n",
    "    ################################################# PLOTTING\n",
    "    def plot_s1s2(self, **kwargs):\n",
    "        '''\n",
    "        Make an S1-S2 2d histogram\n",
    "        '''\n",
    "        plt.hist2d(self.d['s1'], self.d['s2'], **kwargs)\n",
    "        plt.xlabel('S1 (p.e.)')\n",
    "        plt.ylabel('S2 (p.e.)')\n",
    "        return\n",
    "\n",
    "    def plot_s1bs2(self, **kwargs):\n",
    "        '''\n",
    "        Make an S1-S2 2d histogram\n",
    "        '''\n",
    "        plt.hist2d(self.d['s1'], self.d['s2_bot'], **kwargs)\n",
    "        plt.xlabel('S1 (p.e.)')\n",
    "        plt.ylabel('Bottom S2 (p.e.)')\n",
    "        return\n",
    "    \n",
    "    def plot_cs1cs2(self, **kwargs):\n",
    "        plt.hist2d(self.d['cs1'], self.d['cs2'], **kwargs)\n",
    "        plt.xlabel('cS1 (p.e.)')\n",
    "        plt.ylabel('cS2 (p.e.)')\n",
    "        return\n",
    "    \n",
    "    def plot_cs1bs2(self, **kwargs):\n",
    "        plt.hist2d(self.d['cs1'], self.d['s2_bot'], **kwargs)\n",
    "        plt.xlabel('cS1 (p.e.)')\n",
    "        plt.ylabel('S2 bottom (p.e.)')\n",
    "        return\n",
    "    \n",
    "    def plot_e_line(self, e, g1 = 0.07099636,  g2 = 3.08170177, s1_range=(0,2e3), **kwargs):\n",
    "        x_plot = np.linspace(*s1_range, num = 100)\n",
    "        y_plot = g2 * (e / 13.7e-3 - x_plot / g1)\n",
    "        plt.plot(x_plot, y_plot, **kwargs)\n",
    "        return\n",
    "        \n",
    "    ################################################# CUTS\n",
    "    \n",
    "    def cuts_apply_all(self):\n",
    "        for cut in self.cut_list:\n",
    "            cut()\n",
    "        return None\n",
    "    \n",
    "    def cuts_history(self):\n",
    "        return cuts.history(self.d)\n",
    "    \n",
    "    \n",
    "    ################################################# INDIVIDUAL CUTS\n",
    "        \n",
    "    def cut_interaction_exists(self, plot=False, apply=True):\n",
    "        self.d = cuts.isfinite(self.d, 's1')\n",
    "        return\n",
    "    \n",
    "    def cut_largest_other_s1(self, largest_other_s1_max=5, plot=False, apply=True, **kwargs):\n",
    "        if plot:\n",
    "            plt.hist2d(self.d['s1'], self.d['largest_other_s1'], **kwargs)\n",
    "            plt.xlabel('S1 (p.e.)')\n",
    "            plt.ylabel('Largest other S1 (p.e.)')\n",
    "            plt.axhline(largest_other_s1_max, ls='--', color='red', lw=2)\n",
    "        if apply: self.d = cuts.below(self.d, 'largest_other_s1', largest_other_s1_max)\n",
    "        return\n",
    "\n",
    "    def cut_largest_other_s2(self, largest_other_s2_max = 100., plot=False, apply=True, **kwargs):\n",
    "        if plot:\n",
    "            plt.hist2d(self.d['s2'], self.d['largest_other_s2'], **kwargs)\n",
    "            plt.xlabel('S2 (p.e.)')\n",
    "            plt.ylabel('Largest other S2 (p.e.)')\n",
    "            plt.axhline(largest_other_s2_max, ls='--', color='red', lw=2)\n",
    "        if apply: self.d = cuts.below(self.d, 'largest_other_s2', largest_other_s2_max)\n",
    "        return\n",
    "    \n",
    "    def cut_thresholds(self, s1_threshold=5., s2_threshold=100., plot=False, apply=True, **kwargs):\n",
    "        if plot:\n",
    "            self.plot_s1s2(**kwargs)\n",
    "            plt.axvline(s1_threshold, color='red', ls='--', lw=2)\n",
    "            plt.axhline(s2_threshold, color='red', ls='--', lw=2)\n",
    "            plt.show()\n",
    "        if apply:\n",
    "            self.d = cuts.above(self.d, 's1', s1_threshold)\n",
    "            self.d = cuts.above(self.d, 's2', s2_threshold)\n",
    "        return\n",
    "    \n",
    "    def cut_saturation(self, plot=False, apply=True):\n",
    "        if plot:\n",
    "            sat = (self.d['s1_n_saturated_channels'] > 0) | (self.d['s2_n_saturated_channels'] > 0)\n",
    "            nonsat = np.invert(sat)\n",
    "            plt.scatter(self.d['s1'][nonsat], self.d['s2'][nonsat], color='blue',\n",
    "                        edgecolor='None', s=2, label='Not saturated')\n",
    "            plt.scatter(self.d['s1'][sat], self.d['s2'][sat], color='red',\n",
    "                        edgecolor='None', s=10, label='ADC saturated')\n",
    "            plt.xlabel('S1 (p.e.)')\n",
    "            plt.ylabel('S2 (p.e.)')\n",
    "            plt.legend(loc='best')\n",
    "            \n",
    "        if apply:\n",
    "            self.d = cuts.below(self.d, 's1_n_saturated_channels', 1)\n",
    "            self.d = cuts.below(self.d, 's2_n_saturated_channels', 1)\n",
    "        return\n",
    "\n",
    "    \n",
    "    def cut_low_energy(self, s1_max = 1000, s2_max = 60e3, plot=False, apply=True, **kwargs):\n",
    "        if plot:\n",
    "            self.plot_s1s2(**kwargs)\n",
    "            plt.axvline(s1_max, color='red', ls='--', lw=2)\n",
    "            plt.axhline(s2_max, color='red', ls='--', lw=2)\n",
    "            plt.show()\n",
    "        if apply:\n",
    "            self.d = cuts.below(self.d, 's1', s1_max)\n",
    "            self.d = cuts.below(self.d, 's2', s2_max)\n",
    "        return\n",
    "        \n",
    "    def cut_s2_aft(self,  s2_aft_range=(0.55, 0.78), plot=False, apply=True):\n",
    "        if plot:\n",
    "            plt.hist2d(np.log10(self.d['s2']), self.d['s2_area_fraction_top'], bins=100, norm=LogNorm())\n",
    "            plt.xlabel('log10 of S2/p.e.')\n",
    "            plt.ylabel('S2 aft')\n",
    "            for _l in s2_aft_range:\n",
    "                plt.axhline(_l, color='red', ls='--', lw=2)\n",
    "            plt.show()\n",
    "        if apply: self.d = cuts.range_selection(self.d, 's2_area_fraction_top', s2_aft_range)\n",
    "        return\n",
    "    \n",
    "    def cut_s1_aft(self, plot=False, apply=True, s1_bins=20, s1_range=(0, 2000), dt_range=(0,60), dt_bins=60):\n",
    "        # Interpolate S1 versus s1 aft\n",
    "        x1, y1 = get_trend(self.d['drift_time'], self.d['s1_area_fraction_top'], dt_range, dt_bins)\n",
    "        f_s1_aft = my_interp(x1, y1, kind='linear')\n",
    "        # Compute the difference from the trend\n",
    "        self.d['s1_aft_difference'] = self.d['s1_area_fraction_top'] - f_s1_aft(self.d['drift_time'])\n",
    "\n",
    "        # Get the upper and lower percentiles...\n",
    "        x, y_upper = get_trend(self.d['s1'], self.d['s1_aft_difference'], bins=s1_bins, x_range=s1_range, \n",
    "                               mode='percentile', pct=95)\n",
    "        x, y_lower = get_trend(self.d['s1'], self.d['s1_aft_difference'], bins=s1_bins, x_range=s1_range, \n",
    "                               mode='percentile',pct=5)\n",
    "\n",
    "        # ... And their interpolation...\n",
    "        f_lower = my_interp(x, y_lower, kind='cubic')\n",
    "        f_upper = my_interp(x, y_upper, kind='cubic')\n",
    "        \n",
    "        \n",
    "        if plot:\n",
    "            plt.hist2d(self.d['drift_time'], self.d['s1_area_fraction_top'], bins=100, norm=LogNorm(), range=((0, 60), (0,1)))\n",
    "            x_plot = np.linspace(0, 60, 250)\n",
    "            plt.plot(x_plot, f_s1_aft(x_plot), color='red', label='Interpolation')\n",
    "            plt.scatter(x1, y1, s=5, label='Binned mean trend')\n",
    "            plt.xlabel('Drift time ($\\mu$s)')\n",
    "            plt.ylabel('S1 AFT')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "            plt.hist2d(self.d['s1'], self.d['s1_aft_difference'], bins=100, \n",
    "                       range=(s1_range, (-0.5, 0.5)), norm=LogNorm())\n",
    "            plt.axhline(0, color='black')\n",
    "            x_plot = np.linspace(s1_range[0], s1_range[1], 400)\n",
    "\n",
    "            plt.plot(x_plot, f_upper(x_plot), color='red', label='Interpolation')\n",
    "            plt.plot(x_plot, f_lower(x_plot), color='red')\n",
    "            plt.scatter(x, y_upper, s=10, color='red', label='Binned percentile')\n",
    "            plt.scatter(x, y_lower, s=10, color='red')\n",
    "            plt.xlabel('S1 (a.u.)')\n",
    "            plt.ylabel('Difference from mean AFT')\n",
    "            plt.show()\n",
    "    \n",
    "        self.d['AFT_Upper'] = (self.d['s1_aft_difference'] < f_upper(self.d['s1'])) # Add boolean variable\n",
    "        self.d['AFT_Lower'] = (self.d['s1_aft_difference'] > f_lower(self.d['s1']))\n",
    "        if apply:\n",
    "            self.d = cuts.selection(self.d, self.d['AFT_Upper'], 'AFT_Upper')\n",
    "            self.d = cuts.selection(self.d, self.d['AFT_Lower'], 'AFT_Lower')\n",
    "        return\n",
    "        \n",
    "    def cut_drift_time(self, drift_time_bounds=(0, 60), plot=False, apply=True, **kwargs):\n",
    "        if plot:\n",
    "            plt.hist(self.d['drift_time'], **kwargs)\n",
    "            for _l in drift_time_bounds:\n",
    "                plt.axvline(_l, color='red', ls='--', lw=2)\n",
    "        if apply:\n",
    "            self.d = cuts.range_selection(self.d, 'drift_time', drift_time_bounds)\n",
    "        return\n",
    "\n",
    "    def cut_s2_range_50p_area(self, pickle_file = 'cs_s2_range_50p_area_bounds_v_z.pickle', \n",
    "                          plot=False, apply=True, **kwargs):\n",
    "        # Read width bounds from file\n",
    "        z, s2_10, s2_50, s2_90 = pickle.load(open(pickle_file, 'rb'))\n",
    "        f_10 = my_interp(z, s2_10, kind='linear')\n",
    "        f_50 = my_interp(z, s2_50, kind='linear')\n",
    "        f_90 = my_interp(z, s2_90, kind='linear')\n",
    "        if plot:\n",
    "            plt.hist2d(self.d['z'], self.d['s2_range_50p_area'], range=((-11, 0), (0, 2e3)), **kwargs)\n",
    "            plt.xlabel('z (cm)')\n",
    "            plt.ylabel('S2 range 50p area (ns)')\n",
    "            # Plot the percentiles and lines through them\n",
    "            x_plot = np.linspace(-11, 0, 250)\n",
    "            plt.scatter(z, s2_50, color='blue')\n",
    "            plt.plot(x_plot, f_50(x_plot), color='blue')\n",
    "            for _s2, _f, _label in zip((s2_10, s2_90), (f_10, f_90), ('Lower limit', 'Upper limit')):\n",
    "                plt.plot(x_plot, _f(x_plot), color='red', label = _label)\n",
    "                plt.scatter(z, _s2, color='red')\n",
    "\n",
    "        if apply:\n",
    "            self.d = cuts.selection(self.d, self.d['s2_range_50p_area'] < f_90(self.d['z']), 'Upper bound S2 width')\n",
    "            self.d = cuts.selection(self.d, self.d['s2_range_50p_area'] > f_10(self.d['z']), 'Lower bound S2 width')\n",
    "        return\n",
    "    \n",
    "    def cut_NaI_interaction_exists(self):\n",
    "        if not self.include_NaI:\n",
    "            print('Warning: not applying NaI cut since you disabled it!')\n",
    "            return\n",
    "        self.d = cuts.isfinite(self.d, 'NaI_area')\n",
    "        \n",
    "        \n",
    "    ########################################### CORRECTIONS\n",
    "    \n",
    "    def corr_s1_ly(self, ly_filename='/home/erik/win/xams/analysis/light_yield/na22_ly.pickle', kind='quadratic'):\n",
    "        '''\n",
    "        Correct S1 light yield based on interpolation of points in pickle file.\n",
    "        '''\n",
    "        # Import the correction from calibration\n",
    "        # Interpolate light curve\n",
    "        x, y = pickle.load(open(ly_filename, 'rb'))\n",
    "        f_s1_corr = my_interp(x, y, kind=kind)\n",
    "        def get_cs1(s1, z, f_s1_corr):\n",
    "            average_s1 = np.average([f_s1_corr(_z) for _z in np.linspace(-10, 0, 500)])\n",
    "            return s1/f_s1_corr(z) * average_s1\n",
    "        self.d['cs1']= get_cs1(self.d['cs1'], self.d['z'], f_s1_corr)\n",
    "\n",
    "    def corr_s1_ly_poly(self, ly_filename='/home/erik/win/xams/analysis/light_yield/na22_ly_poly.pickle'):\n",
    "        # Ugly fix for now...\n",
    "        # Does not even work.\n",
    "        def p2(x, a0, a1, a2):\n",
    "            return a0 + a1 * x + a2 * x**2\n",
    "        \n",
    "        f, popt, pcov = pickle.load(open(ly_filename, 'rb'))\n",
    "        def get_cs1(s1, z, f):\n",
    "            average_s1 = np.average([f(_z, *popt) for _z in np.linspace(-10, 0, 500)])\n",
    "            return s1/f(z, *popt) * average_s1\n",
    "        self.d['cs1']= get_cs1(self.d['cs1'], self.d['z'], f)\n",
    "\n",
    "    def corr_s2_sag(self, cs1_range = (150, 250), cs2_cutoff = 7e3, time_bins=10, mode='median', plot=False, apply=True,\n",
    "                   **kwargs):\n",
    "        '''\n",
    "        Ugh such an ungly word but at least clear for our own jargon.\n",
    "        '''\n",
    "        _d = self.d[(self.d['cs1'] > cs1_range[0]) & (self.d['cs1'] < cs1_range[1])]\n",
    "        _d2 = _d[_d['cs2'] > cs2_cutoff]\n",
    "        x, y = get_trend(_d2['t'], _d2['cs2'],x_range=(min(_d2['t']), max(_d2['t'])), bins=time_bins, mode='median')\n",
    "        f_s2 = my_interp(x, y, kind='linear')\n",
    "        def f_s2_corr(t, f_s2):\n",
    "            return f_s2(0) / f_s2(t)\n",
    "\n",
    "        if plot:\n",
    "            plt.hist2d(_d['t'], _d['s2'], **kwargs)\n",
    "            plt.axhline(cs2_cutoff, color='red', lw=2, ls='--')\n",
    "            plt.xlabel('Time (s)')\n",
    "            plt.ylabel('cS2 (p.e.)')\n",
    "\n",
    "            x_plot = np.linspace(0, max(_d['t']), 250)\n",
    "            plt.scatter(x,y, color='red')\n",
    "            plt.plot(x_plot, f_s2(x_plot), color='red')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            s2_cutoff = 7e3\n",
    "            plt.hist(_d['cs2'], bins=100, histtype='step')\n",
    "            plt.axvline(cs2_cutoff, color='red', lw=2, ls='--')\n",
    "            plt.xlabel('cS2 (p.e.)')\n",
    "            plt.show()\n",
    "        if apply:\n",
    "            self.d['cs2'] = self.d['cs2'] * f_s2_corr(self.d['t'], f_s2)\n",
    "        \n",
    "    def corr_pmtgains(self, processing_gains, voltages, verbose=False):\n",
    "        '''\n",
    "        Usage: give processing gain list such as in config, [PMT1voltage, PMT2voltage]\n",
    "        Enable verbose to get a bunch of prints\n",
    "        '''\n",
    "        # Get the multiplicative factors\n",
    "        fbot = processing_gains[3] / get_gain(1, voltages[0]) # Bottom PMT is pmt 1 is channel 3\n",
    "        ftop = processing_gains[0] / get_gain(2, voltages[1])\n",
    "        if verbose: print('Using gains %f and %f, factors %f and %f, PMT1 and 2 respectively.'\n",
    "                         % (get_gain(1, voltages[0]), get_gain(2, voltages[1]), fbot, ftop))\n",
    "\n",
    "        # Correction for all peaks\n",
    "        for peak_name in ['s1', 's2', 'largest_other_s1', 'largest_other_s2']:\n",
    "            self._correct_this_peak(peak_name, fbot, ftop)\n",
    "        \n",
    "        # Set the cs1 to s1\n",
    "        # I am assuming that you perform a gain correction BEFORE any other correction (fair assumption?)\n",
    "        self.d['cs1'] = self.d['s1']\n",
    "        self.d['cs2'] = self.d['s2']\n",
    "\n",
    "        return\n",
    "    \n",
    "    ########################################### AUXILARY\n",
    "    \n",
    "    def _correct_this_peak(self, peak_name, fbot, ftop):\n",
    "        self.d[peak_name + '_top'] = self.d[peak_name] * self.d[peak_name + '_area_fraction_top'] * ftop\n",
    "        self.d[peak_name + '_bot'] = self.d[peak_name] * (1-self.d[peak_name + '_area_fraction_top']) * fbot\n",
    "        self.d[peak_name] = self.d[peak_name + '_top'] + self.d[peak_name + '_bot']\n",
    "        self.d[peak_name + 'area_fraction_top'] = self.d[peak_name + '_top'] / self.d[peak_name]\n",
    "        return\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
