{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erik/anaconda3/envs/pax/lib/python3.4/site-packages/IPython/kernel/__init__.py:13: ShimWarning: The `IPython.kernel` package has been deprecated. You should import from ipykernel or jupyter_client instead.\n",
      "  \"You should import from ipykernel or jupyter_client instead.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import hax\n",
    "from hax import cuts\n",
    "import pickle\n",
    "import os\n",
    "from gain_extrapolator_reduced import get_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class XAMSAnalysis():\n",
    "    '''\n",
    "    This holds the data and functions to perform basic analysis on the XAMS data.\n",
    "    Functions here are:\n",
    "    - ``load`` to load the data and all relevant minitrees\n",
    "    - ``cut_*`` to apply a cut (and give ``plot=True`` to see what it cuts)\n",
    "    - ``cuts_*`` for quick application of multiple cuts\n",
    "    - ``plot_*`` for standard plots.\n",
    "    - ``corr_*`` for corrections\n",
    "    '''\n",
    "    __version__ = '0.0.2'\n",
    "    # Holds dataframe containing all data\n",
    "    d = None\n",
    "    # This will list all basic cuts\n",
    "    cut_list = []\n",
    "    corr_s2_decrease_isapplied = False\n",
    "    ################################################# BASICS\n",
    "    \n",
    "    def __init__(self, filenames, processed_data_path, minitree_path, include_NaI = False):\n",
    "        self.filenames = filenames\n",
    "        self.processed_data_path = processed_data_path\n",
    "        self.minitree_path = minitree_path\n",
    "        self.include_NaI = include_NaI\n",
    "        # Cut list is not used for but may be used in future as a set of 'standard cuts'\n",
    "        self.cut_list = [\n",
    "            self.cut_interaction_exists,\n",
    "            self.cut_thresholds,\n",
    "            self.cut_low_energy,\n",
    "            self.cut_largest_other_s1,\n",
    "            self.cut_largest_other_s2,\n",
    "            self.cut_saturation,\n",
    "            self.cut_s2_aft,\n",
    "            self.cut_s1_aft,\n",
    "            self.cut_drift_time\n",
    "        ]\n",
    "        self.start_time = 0.\n",
    "        self.end_time = 0.\n",
    "        return\n",
    "    \n",
    "    def load(self, verbose=True, treemakers=None, **kwargs):\n",
    "        '''\n",
    "        Load the data into datafame using hax.minitrees.load.\n",
    "        Any args will be passed to hax.minitrees.load.\n",
    "        Extra properties computes: \n",
    "        - NaI energy\n",
    "        - Dataset number\n",
    "        - t : time in s since start of run\n",
    "        - Drift time converted to us\n",
    "        - cs1 and cs2 set identical to s1 and s2\n",
    "        '''\n",
    "        hax.init(\n",
    "            # Always use these lines to tell hax that we don't care about Xe1T\n",
    "            experiment='XAMS', \n",
    "            pax_version_policy='loose', use_runs_db = False,\n",
    "            # Here come the useful settings\n",
    "            main_data_paths = [self.processed_data_path],\n",
    "            minitree_paths = [self.minitree_path],       \n",
    "         )\n",
    "        \n",
    "        if not treemakers:\n",
    "            # If no argument for treemakers, get default\n",
    "            if self.include_NaI:\n",
    "                treemakers = ['Fundamentals','Basics', ExtraS1S2Properties, NaIProperties]\n",
    "            else:\n",
    "                treemakers = ['Fundamentals','Basics', ExtraS1S2Properties]\n",
    "            \n",
    "        # Load data\n",
    "        if self.include_NaI:\n",
    "            self.d = hax.minitrees.load(self.filenames, treemakers,\n",
    "                                       **kwargs)\n",
    "        else:\n",
    "            self.d = hax.minitrees.load(self.filenames, treemakers, **kwargs)\n",
    "            \n",
    "        #################### EXTRA PROPERTIES COMPUTED UPON LOADING DATA    \n",
    "        \n",
    "        # Recompute drift time to us\n",
    "        self.d['drift_time'] = self.d['drift_time'] * 1e-3\n",
    "        # Set cs1 and cs2 identical to s1\n",
    "        self.d['cs1'] = self.d['s1']\n",
    "        self.d['cs2'] = self.d['s2']\n",
    "        # Compute bottom properties\n",
    "        self.d['s2_bot'] = self.d['s2'] * (1 - self.d['s2_area_fraction_top'])\n",
    "        self.d['cs2b'] = self.d['s2'] * (1 - self.d['s2_area_fraction_top'])\n",
    "        # Compute time since start of run in seconds\n",
    "        self.d['t'] = (self.d['event_time'] - self.d['event_time'].values[0]) * 1e-9      \n",
    "        # Time since previous event. Set to zero (worst case) for event zero.\n",
    "        self.d['ms_since_previous_event'] = np.concatenate( ([0],np.diff(self.d.event_time))) * 1e-6\n",
    "        # Calibration of NaI\n",
    "        if self.include_NaI:\n",
    "            self.d['NaI_energy'] = self.d['NaI_area'] * 511 / 1287.8107708648045\n",
    "        \n",
    "        # Re-set the run number by checking for change in event number\n",
    "        dset_change_indices = np.where(np.diff(self.d['event_number']) != 1)[0]\n",
    "        # Number of events in each dataset\n",
    "        dset_lengths = np.diff(np.concatenate([np.array([0]), dset_change_indices + 1, np.array([len(self.d)])]))\n",
    "        if len(dset_lengths) != len(self.filenames):\n",
    "            print('Warning: auto-computing of dataset index failed.')\n",
    "        dset_index_array = np.concatenate([np.ones(dset_length, dtype=int) * i \n",
    "                                           for i, dset_length in enumerate(dset_lengths)])\n",
    "        self.d['run_number'] = dset_index_array\n",
    "        self.add_dataset_props()\n",
    "               \n",
    "        \n",
    "        if verbose: print('Loaded %d (%.1f k) events.' % (self.n_events, self.n_events * 0.001))\n",
    "        if verbose: print('Total live time: %.1f seconds (%.1f hours)' % (self.livetime, self.livetime / 3600.))\n",
    "        return\n",
    "    \n",
    "    ################################################# ADDING PROPERTIES         \n",
    "    def add_g1g2_props(self, pickle_file = '/home/erik/win/xams/analysis/light_yield/data/doke_sel2.pickle'):\n",
    "        '''\n",
    "        Add properties based on g1 and g2.\n",
    "        '''\n",
    "        popt_doke = pickle.load(open(pickle_file, 'rb'))\n",
    "        g1, g2 = popt_doke\n",
    "        # Number of gammas\n",
    "        self.d['n_g'] = self.d['cs1'] / g1\n",
    "        self.d['n_e'] = self.d['cs2b'] / g2\n",
    "        self.d['n_quanta'] = self.d['n_g'] + self.d['n_e']\n",
    "        self.d['f_g'] = self.d['n_g'] / (self.d['n_quanta']) # gamma fraction\n",
    "        self.d['e_ces'] = 13.7e-3 * (self.d['cs1'] / g1 + self.d['cs2b'] / g2)\n",
    "        return\n",
    "        \n",
    "    def add_dataset_props(self):\n",
    "        '''\n",
    "        Add the total run livetime. Warning: run only on data with high enough event rate and uncut!\n",
    "        '''\n",
    "        time = 0.\n",
    "        for rn in np.unique(self.d['run_number']):\n",
    "            time += (max(self.d[self.d['run_number'] == rn]['t']) - min(self.d[self.d['run_number'] == rn]['t']))\n",
    "        self.livetime = time\n",
    "        self.n_events = len(self.d)\n",
    "        self.rate = self.n_events / self.livetime\n",
    "        # Unix timestamps of first and last event\n",
    "        self.start_time = self.d['event_time'].values[0] * 1e-9\n",
    "        self.end_time = self.d['event_time'].values[-1] * 1e-9\n",
    "        return\n",
    "        \n",
    "    def add_s1_waveforms(self, verbose = False, cache_path = '/home/erik/win/data/xams_run8/cache/'):\n",
    "        '''\n",
    "        Get the S1 pulse shape only for the events in the dataframe.\n",
    "        '''\n",
    "        d_s1pulse_list = []\n",
    "        for rn_i, rn in enumerate(self.filenames):\n",
    "            # We only load the waveforms for the events still in the dataset after cuts\n",
    "            event_numbers_this_dataset = self.d[self.d['run_number'] == rn_i]['event_number'].values\n",
    "            if verbose: print(rn)\n",
    "            # Load the data and dump into cache file (after building cache files, there is a massive speedup)\n",
    "            d_s1pulse = hax.minitrees.load(datasets=rn, treemakers=[S1Pulse], \n",
    "                                    cache_file = os.path.join(cache_path, '%s_S1Pulse.cache' % rn) )\n",
    "            # Throw out events not in dataframe\n",
    "            d_s1pulse = d_s1pulse[d_s1pulse['event_number'].isin(event_numbers_this_dataset)]\n",
    "            d_s1pulse_list.append(d_s1pulse)\n",
    "        s1_pulses_df = pd.concat(d_s1pulse_list)\n",
    "        s1_pulses = s1_pulses_df.s1_pulse.values\n",
    "        self.d['s1_pulse'] = s1_pulses \n",
    "        return \n",
    "    \n",
    "    def add_percentiles(self, fractions_desired = [0.1, 0.2, 0.3, 0.4]):\n",
    "        '''\n",
    "        Compute the point in the S1 waveform where 10, 20, 30 and 40 percent of the area is reached.\n",
    "        Adds properties to the dataframe: `s1_X0p_point` and `s1_fraction_outside_pulse`.\n",
    "        Time in ns since start of pulse (pulse[0] = 0 ns)\n",
    "        '''\n",
    "        s1_percentile_points = []\n",
    "        s1_area_fraction_outside_pulse = []\n",
    "\n",
    "\n",
    "        for i, ev in self.d.iterrows():\n",
    "            pulse = np.array(ev['s1_pulse'])\n",
    "            area_times = np.ones(4) * float('nan')\n",
    "            area_tot = ev['s1']\n",
    "            self._integrate_until_fraction(pulse, area_tot, fractions_desired=fractions_desired, results=area_times)\n",
    "            s1_percentile_points.append(2. * area_times) # Correct for 2 ns here\n",
    "            s1_area_fraction_outside_pulse.append(1 - np.sum(pulse) / ev['s1'])\n",
    "\n",
    "        s1_percentile_points = np.array(s1_percentile_points)\n",
    "        for i, fraction in enumerate(fractions_desired):\n",
    "            self.d['s1_%d_percentile_point' % (fraction * 100)] = s1_percentile_points[:, i]        \n",
    "        self.d['s1_fraction_outside_pulse'] = s1_area_fraction_outside_pulse\n",
    "        return \n",
    "        \n",
    "    ################################################# PLOTTING\n",
    "    def plot_s1s2(self, **kwargs):\n",
    "        '''\n",
    "        Make an S1-S2 2d histogram\n",
    "        '''\n",
    "        plt.hist2d(self.d['s1'], self.d['s2'], **kwargs)\n",
    "        plt.xlabel('S1 (p.e.)')\n",
    "        plt.ylabel('S2 (p.e.)')\n",
    "        return\n",
    "\n",
    "    def plot_s1bs2(self, **kwargs):\n",
    "        '''\n",
    "        Make an S1-S2 2d histogram\n",
    "        '''\n",
    "        plt.hist2d(self.d['s1'], self.d['s2_bot'], **kwargs)\n",
    "        plt.xlabel('S1 (p.e.)')\n",
    "        plt.ylabel('Bottom S2 (p.e.)')\n",
    "        return\n",
    "    \n",
    "    def plot_cs1cs2(self, **kwargs):\n",
    "        plt.hist2d(self.d['cs1'], self.d['cs2'], **kwargs)\n",
    "        plt.xlabel('cS1 (p.e.)')\n",
    "        plt.ylabel('cS2 (p.e.)')\n",
    "        return\n",
    "    \n",
    "    def plot_cs1cs2b(self, **kwargs):\n",
    "        plt.hist2d(self.d['cs1'], self.d['cs2b'], **kwargs)\n",
    "        plt.xlabel('cS1 (p.e.)')\n",
    "        plt.ylabel('cS2b (p.e.)')\n",
    "        return\n",
    "    \n",
    "    def plot_cs1bs2(self, **kwargs):\n",
    "        plt.hist2d(self.d['cs1'], self.d['s2_bot'], **kwargs)\n",
    "        plt.xlabel('cS1 (p.e.)')\n",
    "        plt.ylabel('S2 bottom (p.e.)')\n",
    "        return\n",
    "    \n",
    "    def plot_e_line(self, e, pickle_file = '/home/erik/win/xams/analysis/light_yield/data/doke_sel2.pickle',\n",
    "                    s1_range=(0,2e3), y_axis = 'cs2b', s2_aft = None, **kwargs):\n",
    "        popt_doke = pickle.load(open(pickle_file, 'rb'))\n",
    "        g1, g2 = popt_doke\n",
    "        x_plot = np.linspace(*s1_range, num = 100)\n",
    "        if y_axis == 'cs2b':\n",
    "            y_plot = g2 * (e / 13.7e-3 - x_plot / g1)\n",
    "        elif y_axis == 'cs2':\n",
    "            y_plot = g2 * (e / 13.7e-3 - x_plot / g1) * 1 / (1 - s2_aft)\n",
    "        plt.plot(x_plot, y_plot, **kwargs)\n",
    "        return\n",
    "        \n",
    "    def plot_cs1_rate(self, bin_width=1, cs1_max = 400, **kwargs):\n",
    "        counts, bin_edges = np.histogram(self.d['cs1'], bins=round(cs1_max / bin_width), range=(0, cs1_max))\n",
    "        bins_cs1 = 0.5 *(bin_edges[1:] + bin_edges[:-1])\n",
    "        \n",
    "        plt.plot(bins_cs1, 1/self.livetime * counts, ls='steps', **kwargs)\n",
    "        plt.ylim(0,)\n",
    "        plt.xlabel('cS1 (p.e.)')\n",
    "        if bin_width == 1:\n",
    "            plt.ylabel('Differential rate (s$^{-1}$p.e.$^{-1}$)')\n",
    "        else:\n",
    "            plt.ylabel('Differential rate (s$^{-1}$(%.1f p.e.)$^{-1}$)' % bin_width)\n",
    "        return bins_cs1, counts\n",
    "    \n",
    "    def plot_ces_rate(self, bin_width=1, ces_max = 400, **kwargs):\n",
    "        bins, normed_counts = self._plot_rate_hist(key='e_ces', key_max = ces_max, bin_width = bin_width)\n",
    "        plt.xlabel('CES (keV)')\n",
    "        if bin_width == 1:\n",
    "            plt.ylabel('Differential rate (s$^{-1}$keV$^{-1}$)')\n",
    "        else:\n",
    "            plt.ylabel('Differential rate (s$^{-1}$(%.1f keV)$^{-1}$)' % bin_width)\n",
    "        return bins, normed_counts\n",
    "    \n",
    "    def _plot_rate_hist(self, key, key_max, bin_width, **kwargs):\n",
    "        counts, bin_edges = np.histogram(self.d[key], bins=round(key_max / bin_width), range=(0, key_max))\n",
    "        bins = 0.5 *(bin_edges[1:] + bin_edges[:-1])\n",
    "        \n",
    "        plt.plot(bins, 1/self.livetime * counts, ls='steps', **kwargs)\n",
    "        plt.ylim(0,)\n",
    "        plt.xlim(0,)\n",
    "        return bins, 1/self.livetime * counts\n",
    "        \n",
    "    ################################################# CUTS\n",
    "    \n",
    "    def cuts_apply_all(self):\n",
    "        for cut in self.cut_list:\n",
    "            cut()\n",
    "        return None\n",
    "    \n",
    "    def cuts_history(self):\n",
    "        return cuts.history(self.d)\n",
    "    \n",
    "    \n",
    "    ################################################# INDIVIDUAL CUTS\n",
    "        \n",
    "    def cut_interaction_exists(self, plot=False, apply=True):\n",
    "        if apply:\n",
    "            self.d = cuts.isfinite(self.d, 's1')\n",
    "        return\n",
    "    \n",
    "    def cut_time_since_previous(self, max_time_ms=1., plot=False, apply=True, **kwargs):\n",
    "        if plot:\n",
    "            plt.hist(self.d['ms_since_previous_event'], **kwargs)\n",
    "            plt.xlabel('Time since previous event (ms)')\n",
    "            plt.ylabel('Counts')\n",
    "            plt.axvline(max_time_ms)\n",
    "        if apply:\n",
    "            self.d = cuts.above(self.d, 'ms_since_previous_event', max_time_ms)\n",
    "        return\n",
    "    \n",
    "    def cut_largest_other_s1(self, largest_other_s1_max=5, plot=False, apply=True, **kwargs):\n",
    "        if plot:\n",
    "            plt.hist2d(self.d['s1'], self.d['largest_other_s1'], **kwargs)\n",
    "            plt.xlabel('S1 (p.e.)')\n",
    "            plt.ylabel('Largest other S1 (p.e.)')\n",
    "            plt.axhline(largest_other_s1_max, ls='--', color='red', lw=2)\n",
    "        if apply: self.d = cuts.below(self.d, 'largest_other_s1', largest_other_s1_max)\n",
    "        return\n",
    "\n",
    "    def cut_largest_other_s2(self, largest_other_s2_max = 100., plot=False, apply=True, **kwargs):\n",
    "        if plot:\n",
    "            plt.hist2d(self.d['s2'], self.d['largest_other_s2'], **kwargs)\n",
    "            plt.xlabel('S2 (p.e.)')\n",
    "            plt.ylabel('Largest other S2 (p.e.)')\n",
    "            plt.axhline(largest_other_s2_max, ls='--', color='red', lw=2)\n",
    "        if apply: self.d = cuts.below(self.d, 'largest_other_s2', largest_other_s2_max)\n",
    "        return\n",
    "    \n",
    "    def cut_thresholds(self, s1_threshold=5., s2_threshold=100., plot=False, apply=True, **kwargs):\n",
    "        if plot:\n",
    "            self.plot_s1s2(**kwargs)\n",
    "            plt.axvline(s1_threshold, color='red', ls='--', lw=2)\n",
    "            plt.axhline(s2_threshold, color='red', ls='--', lw=2)\n",
    "            plt.show()\n",
    "        if apply:\n",
    "            self.d = cuts.above(self.d, 's1', s1_threshold)\n",
    "            self.d = cuts.above(self.d, 's2', s2_threshold)\n",
    "        return\n",
    "    \n",
    "    def cut_saturation(self, plot=False, apply=True):\n",
    "        if plot:\n",
    "            sat = (self.d['s1_n_saturated_channels'] > 0) | (self.d['s2_n_saturated_channels'] > 0)\n",
    "            nonsat = np.invert(sat)\n",
    "            plt.scatter(self.d['s1'][nonsat], self.d['s2'][nonsat], color='blue',\n",
    "                        edgecolor='None', s=2, label='Not saturated')\n",
    "            plt.scatter(self.d['s1'][sat], self.d['s2'][sat], color='red',\n",
    "                        edgecolor='None', s=10, label='ADC saturated')\n",
    "            plt.xlabel('S1 (p.e.)')\n",
    "            plt.ylabel('S2 (p.e.)')\n",
    "            plt.legend(loc='best')\n",
    "            \n",
    "        if apply:\n",
    "            self.d = cuts.below(self.d, 's1_n_saturated_channels', 1)\n",
    "            self.d = cuts.below(self.d, 's2_n_saturated_channels', 1)\n",
    "        return\n",
    "\n",
    "    \n",
    "    def cut_low_energy(self, cs1_max = 200, cs2_max = 30e3, plot=False, apply=True, **kwargs):\n",
    "        if plot:\n",
    "            self.plot_cs1cs2(**kwargs)\n",
    "            plt.axvline(cs1_max, color='red', ls='--', lw=2)\n",
    "            plt.axhline(cs2_max, color='red', ls='--', lw=2)\n",
    "            plt.show()\n",
    "        if apply:\n",
    "            self.d = cuts.below(self.d, 'cs1', cs1_max)\n",
    "            self.d = cuts.below(self.d, 'cs2', cs2_max)\n",
    "        return\n",
    "        \n",
    "    def cut_s2_aft(self,  s2_aft_range=(0.55, 0.78), plot=False, apply=True):\n",
    "        if plot:\n",
    "            plt.hist2d(np.log10(self.d['s2']), self.d['s2_area_fraction_top'], bins=100, norm=LogNorm())\n",
    "            plt.xlabel('log10 of S2/p.e.')\n",
    "            plt.ylabel('S2 aft')\n",
    "            for _l in s2_aft_range:\n",
    "                plt.axhline(_l, color='red', ls='--', lw=2)\n",
    "            plt.show()\n",
    "        if apply: self.d = cuts.range_selection(self.d, 's2_area_fraction_top', s2_aft_range)\n",
    "        return\n",
    "    \n",
    "    def cut_s1_aft(self, plot=False, apply=True, s1_bins=20, s1_range=(0, 2000), dt_range=(0,60), dt_bins=60):\n",
    "        # Interpolate S1 versus s1 aft\n",
    "        x1, y1 = get_trend(self.d['drift_time'], self.d['s1_area_fraction_top'], dt_range, dt_bins)\n",
    "        f_s1_aft = my_interp(x1, y1, kind='linear')\n",
    "        # Compute the difference from the trend\n",
    "        self.d['s1_aft_difference'] = self.d['s1_area_fraction_top'] - f_s1_aft(self.d['drift_time'])\n",
    "\n",
    "        # Get the upper and lower percentiles...\n",
    "        x, y_upper = get_trend(self.d['s1'], self.d['s1_aft_difference'], bins=s1_bins, x_range=s1_range, \n",
    "                               mode='percentile', pct=95)\n",
    "        x, y_lower = get_trend(self.d['s1'], self.d['s1_aft_difference'], bins=s1_bins, x_range=s1_range, \n",
    "                               mode='percentile',pct=5)\n",
    "\n",
    "        # ... And their interpolation...\n",
    "        f_lower = my_interp(x, y_lower, kind='cubic')\n",
    "        f_upper = my_interp(x, y_upper, kind='cubic')\n",
    "        \n",
    "        \n",
    "        if plot:\n",
    "            plt.hist2d(self.d['drift_time'], self.d['s1_area_fraction_top'], bins=100, norm=LogNorm(), range=((0, 60), (0,1)))\n",
    "            x_plot = np.linspace(0, 60, 250)\n",
    "            plt.plot(x_plot, f_s1_aft(x_plot), color='red', label='Interpolation')\n",
    "            plt.scatter(x1, y1, s=5, label='Binned mean trend')\n",
    "            plt.xlabel('Drift time ($\\mu$s)')\n",
    "            plt.ylabel('S1 AFT')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "            plt.hist2d(self.d['s1'], self.d['s1_aft_difference'], bins=100, \n",
    "                       range=(s1_range, (-0.5, 0.5)), norm=LogNorm())\n",
    "            plt.axhline(0, color='black')\n",
    "            x_plot = np.linspace(s1_range[0], s1_range[1], 400)\n",
    "\n",
    "            plt.plot(x_plot, f_upper(x_plot), color='red', label='Interpolation')\n",
    "            plt.plot(x_plot, f_lower(x_plot), color='red')\n",
    "            plt.scatter(x, y_upper, s=10, color='red', label='Binned percentile')\n",
    "            plt.scatter(x, y_lower, s=10, color='red')\n",
    "            plt.xlabel('S1 (a.u.)')\n",
    "            plt.ylabel('Difference from mean AFT')\n",
    "            plt.show()\n",
    "    \n",
    "        self.d['AFT_Upper'] = (self.d['s1_aft_difference'] < f_upper(self.d['s1'])) # Add boolean variable\n",
    "        self.d['AFT_Lower'] = (self.d['s1_aft_difference'] > f_lower(self.d['s1']))\n",
    "        if apply:\n",
    "            self.d = cuts.selection(self.d, self.d['AFT_Upper'], 'AFT_Upper')\n",
    "            self.d = cuts.selection(self.d, self.d['AFT_Lower'], 'AFT_Lower')\n",
    "        return\n",
    "        \n",
    "    def cut_drift_time(self, drift_time_bounds=(0, 60), plot=False, apply=True, **kwargs):\n",
    "        print('Warning: this cut is depricated, please use the fiducial volume cut!')\n",
    "        if plot:\n",
    "            plt.hist(self.d['drift_time'], **kwargs)\n",
    "            for _l in drift_time_bounds:\n",
    "                plt.axvline(_l, color='red', ls='--', lw=2)\n",
    "        if apply:\n",
    "            self.d = cuts.range_selection(self.d, 'drift_time', drift_time_bounds)\n",
    "        return\n",
    "    \n",
    "    def cut_fiducial_volume(self, z_bounds=(-9.5, -0.5), plot=False, apply=True, **kwargs):\n",
    "        if plot:\n",
    "            plt.hist(self.d['z'], **kwargs)\n",
    "            for _l in z_bounds:\n",
    "                plt.axvline(_l, color='red', ls='--', lw=2)\n",
    "        if apply:\n",
    "            self.d = cuts.range_selection(self.d, 'z', z_bounds)\n",
    "        return\n",
    "        \n",
    "    def cut_s2_range_50p_area(self, \n",
    "                              mode = 'auto',\n",
    "                              dt_range = (0, 60),\n",
    "                              nbins = 30,\n",
    "                              dt_cutoff = 30,\n",
    "                              pickle_file = '../light_yield/data/cs137_s2_width.pickle', cutoff=251.5,\n",
    "                              plot=False, apply=True, verbose=True, **kwargs):\n",
    "        '''\n",
    "        Cut all events width a width inconsistent with drift time. S2 width model from Jelle, fit parameters from \n",
    "        pickle file in argument (mode == 'pickle') or fit medians (mode=='auto').\n",
    "        Semi-automatic mode: fit the offset, but not the diffusion.\n",
    "        \n",
    "        Fitting options:\n",
    "          `dt_range` sets the range where to bin\n",
    "          `nbins` sets the number of bins\n",
    "          `dt_cutoff` is the lower values for the cutoff.\n",
    "        June 2017 / August 2017 / October 2017\n",
    "        '''\n",
    "        \n",
    "        if (mode == 'auto' or mode == 'semi') | (plot):\n",
    "            # We need the medians either for plotting or for computing diffusion...\n",
    "            dt, s2_50 = get_trend(self.d['drift_time'], self.d['s2_range_50p_area'], dt_range, bins=nbins, mode='median')\n",
    "      \n",
    "        if mode == 'auto':\n",
    "            # Full-auto mode: fix neither initial width nor diffusion\n",
    "            syst_err = np.sqrt(0.1**2 + 0.4**2)\n",
    "            popt_s2_w, pcov_s2_w = scipy.optimize.curve_fit(self.s2_width_model_t, dt[dt >= dt_cutoff], \n",
    "                                                            s2_50[dt >= dt_cutoff],\n",
    "                                                            p0=[10, 250e-9])\n",
    "            # Errors...\n",
    "            perr_s2_w = np.sqrt(np.diag(pcov_s2_w))\n",
    "            total_err = np.sqrt(perr_s2_w[0]**2 + syst_err**2)\n",
    "            if verbose:\n",
    "                print('Parameters found: ', popt_s2_w)\n",
    "                print('Diffusion is %.2f +- %.2f +- %.2f cm**2 / s' % (popt_s2_w[0], perr_s2_w[0], syst_err))\n",
    "                print('Diffusion is %.2f +- %.2f cm**2 / s' % (popt_s2_w[0], total_err))\n",
    "        elif mode == 'pickle':\n",
    "            # Full-pickle mode: read the parameters from file.\n",
    "            popt_s2_w, pcov_s2_w = pickle.load(open(pickle_file, 'rb'))\n",
    "        elif mode == 'semi':\n",
    "            # Semi-auto mode: read the diffusion constant from file, but not the initial width.\n",
    "            popt_s2_w, pcov_s2_w = pickle.load(open(pickle_file, 'rb'))\n",
    "            diff_const = popt_s2_w[0]\n",
    "            if verbose: \n",
    "                print('Using diffusion constant %.2f cm**2 / s' % (diff_const))\n",
    "            # Define the function to optimize: the diffusion model with diffusion constant fixed.\n",
    "            def width_model_diffusion_fixed(t, w0):\n",
    "                return self.s2_width_model_t(t, diff_const, w0)\n",
    "            \n",
    "            popt_s2_w0, pcov_s2_w0 = scipy.optimize.curve_fit(width_model_diffusion_fixed, dt[dt >= dt_cutoff], \n",
    "                                                            s2_50[dt >= dt_cutoff],\n",
    "                                                            p0=[250e-9])\n",
    "            popt_s2_w = np.concatenate([[diff_const], popt_s2_w0])\n",
    "            if verbose: print('w0 found: %.2f ns' % (popt_s2_w[1] * 1e9))\n",
    "            \n",
    "        # Now that we have the width model, compute the difference to the model.\n",
    "        self.d['s2_width_difference'] = self.d['s2_range_50p_area'] - self.s2_width_model_t(self.d['drift_time'],\n",
    "                                                                                          *popt_s2_w)\n",
    "\n",
    "        if plot:\n",
    "            plt.hist(self.d['s2_width_difference'], bins=230, histtype='step', range=(-300, 2000))\n",
    "            plt.axvline(cutoff, ls='--', color='red')\n",
    "            plt.yscale('log')\n",
    "            plt.xlabel(r'Difference from S2 width model (\\si{\\nano s})')\n",
    "            plt.ylabel(r'Counts / (\\SI{10}{ns})')\n",
    "            plt.xlim(-300, 2000)\n",
    "            plt.show()\n",
    "            \n",
    "            plt.hist2d(self.d['drift_time'], self.d['s2_range_50p_area'], bins=100, range=((0, 62), (0, 1e3)),\n",
    "                       norm=LogNorm(), **kwargs)\n",
    "            plt.colorbar(label='Counts')\n",
    "            plt.xlabel(r'Drift time (\\si{\\micro s})')\n",
    "            plt.ylabel(r'S2 width (\\si{\\nano s})')\n",
    "            x_plot = np.linspace(0, 62, 100)\n",
    "            plt.plot(x_plot, self.s2_width_model_t(x_plot, *popt_s2_w), label='Width model')\n",
    "            plt.plot(x_plot, self.s2_width_model_t(x_plot, *popt_s2_w) + cutoff, label='Cutoff')\n",
    "            for _l in (dt_cutoff, dt_range[1]):\n",
    "                plt.axvline(_l, ls='--', color='gray')\n",
    "            plt.scatter(dt, s2_50)\n",
    "            plt.legend(framealpha=0.9, loc = 'lower right')\n",
    "            plt.show()\n",
    "        if apply:\n",
    "            self.d = cuts.below(self.d, 's2_width_difference', cutoff)\n",
    "        return popt_s2_w\n",
    "    \n",
    "    def cut_s2_range_50p_area_low(self, cutoff = -50, apply=True, plot=False):\n",
    "        '''\n",
    "        Cut \n",
    "        '''\n",
    "        if 's2_width_difference' not in self.d.keys():\n",
    "            raise RuntimeWarning('Cut not applied, run cut_s2_range_50p_area first...')\n",
    "            return\n",
    "        if apply:\n",
    "            self.d = cuts.above(self.d, 's2_width_difference', cutoff)\n",
    "        return\n",
    "    \n",
    "    def cut_NaI_interaction_exists(self):\n",
    "        if not self.include_NaI:\n",
    "            print('Warning: not applying NaI cut since you disabled it!')\n",
    "            return\n",
    "        self.d = cuts.isfinite(self.d, 'NaI_area')\n",
    "        \n",
    "        \n",
    "    ########################################### CORRECTIONS\n",
    "    \n",
    "    def corr_s1_ly(self, ly_filename='/home/erik/win/xams/analysis/light_yield/na22_ly.pickle', kind='quadratic'):\n",
    "        '''\n",
    "        Correct S1 light yield based on interpolation of points in pickle file.\n",
    "        '''\n",
    "        # Import the correction from calibration\n",
    "        # Interpolate light curve\n",
    "        x, y = pickle.load(open(ly_filename, 'rb'))\n",
    "        f_s1_corr = my_interp(x, y, kind=kind)\n",
    "        def get_cs1(s1, z, f_s1_corr):\n",
    "            average_s1 = np.average([f_s1_corr(_z) for _z in np.linspace(-10, 0, 500)])\n",
    "            return s1/f_s1_corr(z) * average_s1\n",
    "        self.d['cs1']= get_cs1(self.d['cs1'], self.d['z'], f_s1_corr)\n",
    "\n",
    "    def corr_s1_ly_poly(self, ly_filename='data/cs137_ly_p2_rough.pickle', order=2):\n",
    "        if order != 2:\n",
    "            raise NotImplementedError('Only order-2 fits allowed for now...')\n",
    "        \n",
    "        # Assumes a second-degree polynomial fit.\n",
    "        def p2(x, a0, a1, a2):\n",
    "            return a0 + a1 * x + a2 * x**2\n",
    "        \n",
    "        popt, pcov = pickle.load(open(ly_filename, 'rb'))\n",
    "        def get_cs1(s1, z, f):\n",
    "            # Perform a volume average\n",
    "            average_s1 = np.average([f(_z, *popt) for _z in np.linspace(-10, 0, 500)])\n",
    "            return s1/f(z, *popt) * average_s1\n",
    "        self.d['cs1']= get_cs1(self.d['s1'], self.d['z'], p2)\n",
    "        return\n",
    "\n",
    "    def corr_s2_electron_lifetime(self, lifetime=None, pickle_file=None, verbose=False):\n",
    "        '''\n",
    "        Enter electron lifetime in microseconds please\n",
    "        '''\n",
    "        if pickle_file:\n",
    "            popt_life, _ = pickle.load(open(pickle_file, 'rb'))\n",
    "            if lifetime:\n",
    "                print('Warning: you gave both electron lifetime AND a pickle file, I will use the pickle ONLY.')\n",
    "            lifetime = popt_life[1]\n",
    "        if verbose: print('Using lifetime %f' % lifetime)\n",
    "        if lifetime <= 0: raise ValueError('What? Negative lifetime? No, screw you! This is what I got: %f' % lifetime)\n",
    "        self.d['cs2'] = self.d['s2'] * np.exp(self.d['drift_time'] / lifetime)\n",
    "        self.d['cs2b'] = self.d['s2_bot'] * np.exp(self.d['drift_time'] / lifetime)\n",
    "        \n",
    "        \n",
    "    def corr_s2_sag(self, cs1_range = (150, 250), cs2_cutoff = 7e3, time_bins=10, mode='median', plot=False, apply=True,\n",
    "                   **kwargs):\n",
    "        '''\n",
    "        Ugh such an ungly word but at least clear for our own jargon.\n",
    "        '''\n",
    "        print('Warning: function is depricated. Use the `corr_s2_decrease` function please.')\n",
    "        _d = self.d[(self.d['cs1'] > cs1_range[0]) & (self.d['cs1'] < cs1_range[1])]\n",
    "        _d2 = _d[_d['cs2'] > cs2_cutoff]\n",
    "        x, y = get_trend(_d2['t'], _d2['cs2'],x_range=(min(_d2['t']), max(_d2['t'])), bins=time_bins, mode='median')\n",
    "        f_s2 = my_interp(x, y, kind='linear')\n",
    "        def f_s2_corr(t, f_s2):\n",
    "            return f_s2(0) / f_s2(t)\n",
    "\n",
    "        if plot:\n",
    "            plt.hist2d(_d['t'], _d['cs2'], **kwargs)\n",
    "            plt.axhline(cs2_cutoff, color='red', lw=2, ls='--')\n",
    "            plt.xlabel('Time (s)')\n",
    "            plt.ylabel('cS2 (p.e.)')\n",
    "\n",
    "            x_plot = np.linspace(0, max(_d['t']), 250)\n",
    "            plt.scatter(x,y, color='red')\n",
    "            plt.plot(x_plot, f_s2(x_plot), color='red')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            s2_cutoff = 7e3\n",
    "            plt.hist(_d['cs2'], bins=100, histtype='step', label='Before corr')\n",
    "            plt.axvline(cs2_cutoff, color='red', lw=2, ls='--')\n",
    "            plt.xlabel('cS2 (p.e.)')\n",
    "        if apply:\n",
    "            self.d['cs2'] = self.d['cs2'] * f_s2_corr(self.d['t'], f_s2)\n",
    "            if plot:\n",
    "                _d = self.d[(self.d['cs1'] > cs1_range[0]) & (self.d['cs1'] < cs1_range[1])]\n",
    "                plt.hist(_d['cs2'], bins=100, histtype='step', label='After corr')\n",
    "        return (x, y)\n",
    "\n",
    "#     def corr_s2_decrease(self, parameters, cs1_range = (175, 225), plot=False, apply=True, **kwargs):\n",
    "#         '''\n",
    "#         Use a linear correction function to correct the S2 decrease. Note that this supersedes the quick-and-dirty \n",
    "#         `corr_s2_sag` function.\n",
    "#         '''\n",
    "#         def lin(x, a0, a1):\n",
    "#             return a0 + a1 * x\n",
    "        \n",
    "#         if plot:\n",
    "#             # Select slice\n",
    "#             _d = self.d[(self.d['cs1'] > cs1_range[0]) & (self.d['cs1'] < cs1_range[1])]\n",
    "#             plt.hist2d(_d['t'], _d['cs2'], **kwargs)\n",
    "#             plt.xlabel('Time (s)')\n",
    "#             plt.ylabel('cS2 (p.e.)')\n",
    "#             # Plot approximation\n",
    "#             x_plot = np.linspace(0, max(_d['t']), 250)\n",
    "#             plt.plot(x_plot, lin(x_plot, *parameters))\n",
    "        \n",
    "#         if apply:\n",
    "#             if self.corr_s2_decrease_isapplied:\n",
    "#                 print('Already applied correction, will not do it again!')\n",
    "#                 return\n",
    "#             self.corr_s2_decrease_isapplied = True\n",
    "#             self.d['cs2'] = self.d['cs2'] * lin(0, *parameters) / (lin(self.d['t'], *parameters))\n",
    "#         return\n",
    "    \n",
    "    def corr_s2_decrease(self, f, apply=True):\n",
    "        if apply:\n",
    "            if self.corr_s2_decrease_isapplied:\n",
    "                print('Already applied correction, will not do it again!')\n",
    "                return\n",
    "            self.corr_s2_decrease_isapplied = True\n",
    "            self.d['cs2'] = self.d['cs2'] * f(self.d['t'])\n",
    "        return\n",
    "        \n",
    "    def corr_pmtgains(self, processing_gains, voltages, verbose=False):\n",
    "        '''\n",
    "        Usage: give processing gain list such as in config, [PMT1voltage, PMT2voltage]\n",
    "        Enable verbose to get a bunch of prints\n",
    "        Should NOT be used if correct gains set...\n",
    "        '''\n",
    "        print('Hey, why not use the correct gain in processing?')\n",
    "        # Get the multiplicative factors\n",
    "        fbot = processing_gains[3] / get_gain(1, voltages[0]) # Bottom PMT is pmt 1 is channel 3\n",
    "        ftop = processing_gains[0] / get_gain(2, voltages[1])\n",
    "        if verbose: print('Using gains %f and %f, factors %f and %f, PMT1 and 2 respectively.'\n",
    "                         % (get_gain(1, voltages[0]), get_gain(2, voltages[1]), fbot, ftop))\n",
    "\n",
    "        # Correction for all peaks\n",
    "        for peak_name in ['s1', 's2', 'largest_other_s1', 'largest_other_s2']:\n",
    "            self._correct_this_peak(peak_name, fbot, ftop)\n",
    "        \n",
    "        # Set the cs1 to s1\n",
    "        # I am assuming that you perform a gain correction BEFORE any other correction (fair assumption?)\n",
    "        self.d['cs1'] = self.d['s1']\n",
    "        self.d['cs2'] = self.d['s2']\n",
    "\n",
    "        return\n",
    "    \n",
    "    def corr_z(self, offset, drift_velocity, verbose=False):\n",
    "        '''\n",
    "        TODO place this in the XAMS ini!\n",
    "        Enter offset in microseconds, velocity in km/s\n",
    "        '''\n",
    "        self.d['z'] = (self.d['drift_time'] - offset) * 1e-6 * drift_velocity * 1e5 * (- 1)\n",
    "        return\n",
    "        \n",
    "    ########################################### OTHER\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.d)\n",
    "    \n",
    "    ########################################### AUXILARY\n",
    "    \n",
    "    def _correct_this_peak(self, peak_name, fbot, ftop):\n",
    "        self.d[peak_name + '_top'] = self.d[peak_name] * self.d[peak_name + '_area_fraction_top'] * ftop\n",
    "        self.d[peak_name + '_bot'] = self.d[peak_name] * (1-self.d[peak_name + '_area_fraction_top']) * fbot\n",
    "        self.d[peak_name] = self.d[peak_name + '_top'] + self.d[peak_name + '_bot']\n",
    "        self.d[peak_name + 'area_fraction_top'] = self.d[peak_name + '_top'] / self.d[peak_name]\n",
    "        return\n",
    "   \n",
    "    def _integrate_until_fraction(self, w, area_tot, fractions_desired, results):\n",
    "        \"\"\"For array of fractions_desired, integrate w until fraction of area is reached, place sample index in results\n",
    "        Will add last sample needed fractionally.\n",
    "        eg. if you want 25% and a sample takes you from 20% to 30%, 0.5 will be added.\n",
    "        Assumes fractions_desired is sorted and all in [0, 1]!\n",
    "        This function is stolen and modified from Pax - Erik Hogenbirk September 2017\n",
    "        \"\"\"\n",
    "        fraction_seen = 0\n",
    "        current_fraction_index = 0\n",
    "        needed_fraction = fractions_desired[current_fraction_index]\n",
    "        for i, x in enumerate(w):\n",
    "            # How much of the area is in this sample?\n",
    "            fraction_this_sample = x/area_tot\n",
    "            # Will this take us over the fraction we seek?\n",
    "            # Must be while, not if, since we can pass several fractions_desired in one sample\n",
    "            while fraction_seen + fraction_this_sample >= needed_fraction:\n",
    "                # Yes, so we need to add the next sample fractionally\n",
    "                area_needed = area_tot * (needed_fraction - fraction_seen)\n",
    "                if x != 0:\n",
    "                    results[current_fraction_index] = i + area_needed/x\n",
    "                else:\n",
    "                    results[current_fraction_index] = i\n",
    "                # Advance to the next fraction\n",
    "                current_fraction_index += 1\n",
    "                if current_fraction_index > len(fractions_desired) - 1:\n",
    "                    return\n",
    "                needed_fraction = fractions_desired[current_fraction_index]\n",
    "            # Add this sample's area to the area seen, advance to the next sample\n",
    "            fraction_seen += fraction_this_sample\n",
    "        if needed_fraction == 1:\n",
    "            results[current_fraction_index] = len(w)\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "\n",
    "    def s2_width_model_t(self, t, diffusion_constant, w0):\n",
    "        '''\n",
    "        S2 width model stolen from Jelly Monster. Great info on wiki.\n",
    "        Input drift time in us\n",
    "        '''\n",
    "        # diffusion_constant = PAX_CONFIG['WaveformSimulator']['diffusion_constant_liquid']\n",
    "        v_drift = drift_velocity_liquid = 1.68 * 10**5 # cm/s\n",
    "        t = t * 1e-6 # Convert to seconds\n",
    "        # w0 = 348.6 * units.ns\n",
    "        # WATCH the constant: it is NOT 4.something\n",
    "        return 1e9 * np.sqrt(w0 ** 2 + 3.6395 * diffusion_constant * t / v_drift ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_frameworks(x0, x1=None):\n",
    "    '''\n",
    "    Combine the data from multiple XAMSAnalysis objects into one.\n",
    "    Either give two objects as argument, or a list of objects.\n",
    "    '''\n",
    "    if x1 is None:\n",
    "        assert type(x0) == list\n",
    "        \n",
    "        x_combined = x0[0]\n",
    "        for x_to_add in x0[1:]:\n",
    "            x_combined = combine_frameworks(x_combined, x_to_add)\n",
    "        return x_combined\n",
    "    else:\n",
    "        run_names = np.concatenate([x0.filenames, x1.filenames])\n",
    "        processed_data_path = x0.processed_data_path\n",
    "        minitree_path = x0.minitree_path\n",
    "\n",
    "        x = XAMSAnalysis(run_names, processed_data_path, minitree_path)\n",
    "        # Extract datasets\n",
    "        d0 = x0.d\n",
    "        d1 = x1.d\n",
    "        # Increment run numbers\n",
    "        d0_run_numbers = d0['run_number']\n",
    "        d1_run_numbers = d1['run_number'] + np.max(d0['run_number']) + 1\n",
    "        x.d = pd.concat([d0, d1])\n",
    "        x.d['run_number'] = pd.concat([d0_run_numbers, d1_run_numbers])\n",
    "        # Compute meta-data\n",
    "        x.livetime = x0.livetime + x1.livetime\n",
    "        x.n_events = x0.n_events + x1.n_events\n",
    "        x.rate = x.n_events / x.livetime\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
