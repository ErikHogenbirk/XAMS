{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erik/anaconda3/envs/pax/lib/python3.4/site-packages/IPython/kernel/__init__.py:13: ShimWarning: The `IPython.kernel` package has been deprecated. You should import from ipykernel or jupyter_client instead.\n",
      "  \"You should import from ipykernel or jupyter_client instead.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import hax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ExtraS1S2Properties(hax.minitrees.TreeMaker):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    __version__ = '0.1.4' # beta\n",
    "    extra_branches = ['peaks.*', 'interactions*']\n",
    "    \n",
    "    def remove_duplicates_from_list(self, seq):\n",
    "        seen = set()\n",
    "        seen_add = seen.add\n",
    "        return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "    \n",
    "    \n",
    "    def extract_data(self, event):\n",
    "        # ================ PEAK PROPERTIES =========================\n",
    "        # Extract data for these types\n",
    "        peak_types = ['s1', 's2']\n",
    "        \n",
    "        # Peak_properties (will be loaded for largest s1 and s2)\n",
    "        peak_properties = ['n_saturated_channels', 'center_time', 'left']\n",
    "        # Peak properties for S1 and S2 that are in lists...\n",
    "        extra_properties = ['time_from_midpoint_10p', 'time_from_midpoint_20p',\n",
    "                            'time_from_midpoint_30p', 'time_from_midpoint_40p']\n",
    "        largest_other_properties = ['area_fraction_top', 'center_time']\n",
    "\n",
    "        result_vars = [_pt + '_' + _pp for _pt in peak_types for _pp in peak_properties ]\n",
    "        result = {k: float('nan') for k in result_vars}\n",
    "        result['largest_other_s1_area_fraction_top'] = float(-1)\n",
    "        result['largest_other_s2_area_fraction_top'] = float(-1)\n",
    "        \n",
    "        \n",
    "        s1s = []\n",
    "        s2s = []\n",
    "        n_interactions = len(event.interactions)\n",
    "        \n",
    "        # For all interactions, take their s1 and s2 index\n",
    "        for interaction in event.interactions:\n",
    "            # Get s1 and s2 index\n",
    "            s1s.append(interaction.s1)\n",
    "            s2s.append(interaction.s2)\n",
    "\n",
    "        \n",
    "        # ================= LOAD PEAK DATA ==========================\n",
    "        # Loop over the two peak types\n",
    "        for pt in peak_types:\n",
    "            # Load index list\n",
    "            if pt == 's1':\n",
    "                # Peak list: list ordered by interaction\n",
    "                peak_list = s1s\n",
    "                # Peak list all: all peaks labeled as S1\n",
    "                peak_list_all = sorted(event.s1s, key = lambda index: - getattr(event.peaks[index], 'area'))\n",
    "\n",
    "            elif pt == 's2':\n",
    "                peak_list = s2s\n",
    "                peak_list_all = sorted(event.s2s, key = lambda index: - getattr(event.peaks[index], 'area'))\n",
    "            else:\n",
    "                raise NotImplementedError('Peak types s1 and s2 supported only!')\n",
    "            \n",
    "            # Now, for this peak type, loop over peak_indices and get peak pos\n",
    "            if len(peak_list) == 0:\n",
    "                # If there are not enough peaks of this type, do not try to find properties\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                # Main S1 or S2\n",
    "                peak_pos = int(peak_list[0])\n",
    "                peak_name = pt + '_' # Example: s1_\n",
    "                # All standard properties\n",
    "                for prop in peak_properties:\n",
    "                    result[peak_name + prop] = getattr(event.peaks[peak_pos], prop)\n",
    "                    \n",
    "                # Here come nonstandard properties\n",
    "                for i in range(10):\n",
    "                    if ('range_%d0p_area' % i) in extra_properties:\n",
    "                        result[peak_name + 'range_%d0p_area' % i] = (\n",
    "                            list(event.peaks[peak_pos].range_area_decile)[i])\n",
    "                    if ('time_from_midpoint_%d0p' % i) in extra_properties:\n",
    "                        result[peak_name + 'time_from_midpoint_%d0p' % i] = (\n",
    "                            list(event.peaks[peak_pos].area_decile_from_midpoint)[i])\n",
    "                \n",
    "                \n",
    "                # Remove the main S1/S2 from list\n",
    "                peak_list_all.remove(peak_pos)\n",
    "                if len(peak_list_all) > 0:\n",
    "                    largest_other_index = peak_list_all[0]\n",
    "                    for prop in largest_other_properties:\n",
    "                        result['largest_other_' + pt + '_' + prop] = getattr(event.peaks[largest_other_index], prop)\n",
    "                \n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class XAMSProperties(hax.minitrees.TreeMaker):\n",
    "    '''\n",
    "    Get properties for XAMS\n",
    "    \n",
    "    '''\n",
    "    __version__ = '0.1.0'\n",
    "    \n",
    "    extra_branches = ['peaks.*', 'peaks.range_area_decile*', \n",
    "                      'interactions*']\n",
    "    \n",
    "    def extract_data(self, event):\n",
    "        \n",
    "        peak_types = ['s1', 's2']\n",
    "        peak_properties = ['area_fraction_top', 'area', 'center_time', 'n_saturated_channels']\n",
    "        extra_properties = ['range_50p_area', 'range_70p_area']\n",
    "        all_properties = peak_properties + extra_properties\n",
    "        result_vars = [_pt + '_' + _pp for _pt in peak_types for _pp in all_properties ]\n",
    "        result = {k: float('nan') for k in result_vars}\n",
    "        \n",
    "        interaction_properties = ['drift_time']\n",
    "        for _prop in interaction_properties:\n",
    "            result[_prop] = float('nan')\n",
    "            \n",
    "        s1s = []\n",
    "        s2s = []\n",
    "        \n",
    "        for peak in event.peaks:\n",
    "            if peak.type == 's1':\n",
    "                s1s.append(peak)\n",
    "            if peak.type == 's2':\n",
    "                s2s.append(peak)\n",
    "        \n",
    "        # Reverse-sort by area\n",
    "        s1s = sorted(s1s, key = lambda peak: - peak.area)\n",
    "        s2s = sorted(s2s, key = lambda peak: - peak.area)\n",
    "\n",
    "        \n",
    "        # Now load properies\n",
    "        result['n_s1s'] = len(event.s1s)\n",
    "        result['n_s2s'] = len(event.s2s)\n",
    "        \n",
    "        \n",
    "        for peak_name, peak_list in zip(['s1', 's2'], [s1s, s2s]):\n",
    "            if len(peak_list) == 0:\n",
    "                continue\n",
    "            # First peak in list sorted by area\n",
    "            peak = peak_list[0]\n",
    "            for _prop in peak_properties:\n",
    "                result[peak_name + '_' + _prop] = getattr(peak, _prop)\n",
    "            for i in range(10):\n",
    "                if ('range_%d0p_area' % i) in extra_properties:\n",
    "                    result[peak_name + '_' + 'range_%d0p_area' % i] = list(peak.range_area_decile)[i]\n",
    "        \n",
    "        if len(s2s) > 1:\n",
    "            result['largest_other_s2'] = getattr(s2s[1], 'area')\n",
    "        else:\n",
    "            result['largest_other_s2'] = 0.\n",
    "            \n",
    "        result['drift_time'] = result['s2_center_time'] - result['s1_center_time']\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#             for peak_type, peak_index in zip(peak_types, [s1,s2]):\n",
    "#                 for _prop in peak_properties:\n",
    "#                     result[peak_name + '_' + _prop] = getattr(event.peaks[peak_index], _prop)\n",
    "\n",
    "#                 if 'range_50p_area' in extra_properties:\n",
    "#                     result[peak_name + '_' + 'range_50p_area'] = list(event.peaks[peak_pos].range_area_decile)[5]\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaIProperties(hax.minitrees.TreeMaker):\n",
    "    '''\n",
    "    Add the properties that are closest to the TPC interaction.\n",
    "    Proximity based on a small delay (since pulse comes a bit later)\n",
    "    '''\n",
    "    __version__ = '0.1.3'\n",
    "    extra_branches = ['peaks.*', 'interactions*']\n",
    "    s1_offset = 16. # ns from left edge\n",
    "    \n",
    "    def extract_data(self, event):\n",
    "        ret = {\n",
    "            'NaI_area' : float('nan'),\n",
    "            'NaI_time_from_s1': float('nan'),\n",
    "            'NaI_time_from_s1_corr': float('nan'),\n",
    "            'NaI_left' : float('nan'),\n",
    "            'NaI_n_peaks' : 0,\n",
    "              }\n",
    "        # Check if the interaction exists\n",
    "        if len(event.interactions) == 0:\n",
    "            return ret\n",
    "        \n",
    "        main_s1_index = event.interactions[0].s1\n",
    "        s1_left = getattr(event.peaks[main_s1_index], 'left')        \n",
    "        \n",
    "        time_from_s1 = []\n",
    "        time_from_s1_corr = []\n",
    "        area = []\n",
    "        left = []\n",
    "        \n",
    "        for p in event.peaks:\n",
    "            if getattr(p, 'detector') == 'nai':\n",
    "                time_from_s1.append((getattr(p, 'left') - s1_left) * 2.)\n",
    "                time_from_s1_corr.append((getattr(p, 'left') - s1_left) * 2. - self.s1_offset)\n",
    "                area.append(getattr(p, 'area'))\n",
    "                left.append(getattr(p, 'left'))\n",
    "        \n",
    "        if len(area) == 0:\n",
    "            return ret\n",
    "        \n",
    "        index_of_closest_peak = np.argmin(abs(np.array(time_from_s1_corr)))\n",
    "        ret['NaI_area'] = area[index_of_closest_peak]\n",
    "        ret['NaI_left'] = left[index_of_closest_peak]\n",
    "        ret['NaI_time_from_s1'] = time_from_s1[index_of_closest_peak]\n",
    "        ret['NaI_time_from_s1_corr'] = time_from_s1_corr[index_of_closest_peak]\n",
    "        ret['NaI_n_peaks'] = len(area)\n",
    "        return ret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
