{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_dir = '/home/erik/xams/analysis/pulse_shapes/stbc/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy import optimize\n",
    "import scipy.integrate as integrate\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from multihist import Hist1d, Histdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Digitizer sample size\n",
    "dt = 2\n",
    "# Pulse time for single pe sampling\n",
    "dt_fine = 0.2\n",
    "\n",
    "\n",
    "# Waveform time labels\n",
    "spe_ts = np.linspace(0, 639*2, 640) - 340 * 2\n",
    "# Valid time (because the waveform does not range the full time span)\n",
    "valid_t_range = (-100, 300)\n",
    "t_mask = (valid_t_range[0] <= spe_ts) & (spe_ts < valid_t_range[1])\n",
    "spe_ts = spe_ts[t_mask]\n",
    "spe_t_edges = np.concatenate([[spe_ts[0] - dt/2], spe_ts + dt/2])\n",
    "\n",
    "spe_ts_fine = np.linspace(*valid_t_range, num = (valid_t_range[1] - valid_t_range[0]) / dt_fine + 1)\n",
    "spe_ts_fine = spe_ts_fine[:-1]\n",
    "spe_t_edges_fine = np.concatenate([[spe_ts_fine[0] - dt_fine/2], spe_ts_fine + dt_fine/2])\n",
    "\n",
    "default_params = dict(\n",
    "    t1 = 3.1,    # Singlet lifetime, Nest 2014 p2\n",
    "    t3 = 24,     # Triplet lifetime, Nest 2014 p2\n",
    "    fs = 0.2,    # Singlet fraction\n",
    "    tts = 2.,     # Transit time spread.\n",
    "    # RECOMBINATON PARAMETERS\n",
    "    f_r = 0.,\n",
    "    tr = 15,\n",
    "    fs_r = 0.2,\n",
    "    eta = 0.,\n",
    "    \n",
    "    s1_min=30,\n",
    "    s1_max=100,\n",
    "    dset='er',\n",
    "    # pulse_model=1, # This is the CHANNEL that is used...\n",
    "    aft = 0.5, # 0.28\n",
    "    n_photons = int(2e5),\n",
    "    t_min = -8.,\n",
    "    t_max = 125.,\n",
    "    s1_sample = 'data', # 'uniform'\n",
    "    error_offset  = 0. , \n",
    "    error_pct = 0.,\n",
    "    neglect_statistical = False,\n",
    "    neglect_systematic = False,\n",
    "    spe_model = 'template', # expnorm, hybrid?\n",
    "    s1_model = 'two_exp', # recombination, recombination2\n",
    ")\n",
    "\n",
    "def get_params(params):\n",
    "    '''\n",
    "    Returns full set of parameters, setting the values given in `params` and setting the values in \n",
    "    `default_params` if not set explicity.\n",
    "    '''\n",
    "    for k, v in default_params.items(): # key, value\n",
    "        params.setdefault(k, v)\n",
    "    if params['tts'] < 0:\n",
    "        params['tts'] = 1e-6\n",
    "    # Parameters that may not be smaller than zero\n",
    "    for par in ['fs', 'aft', 'f_r', 'fs_r', 'eta']:\n",
    "        if params[par] < 0:\n",
    "            params[par] = 0\n",
    "        elif params[par] >1:\n",
    "            params[par] =1\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PMT pulses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulse shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the elements of simulted S1s is the single p.e. pulse model. We extract this from the gain calibration dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAESCAYAAADNDrOsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPGZmlqv/D3w6T9XNtgVLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f91af900fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "spe_pulses_cum = []\n",
    "spe_ys = []\n",
    "for ch, fn in enumerate(['170323_103732', '170323_104831']):\n",
    "    with open(os.path.join(pickle_dir, '%s_ch%d.pickle' % (fn, ch)) , 'rb') as infile:\n",
    "        ys = pickle.load(infile)[t_mask]\n",
    "    spe_ys.append(ys/ys.sum())\n",
    "    # spe_pulses_cum: list of 2 elements: cumulative distribution for two channels\n",
    "    spe_pulses_cum.append(\n",
    "        interp1d(spe_ts, np.cumsum(ys)/ys.sum())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulse shape - modified exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_mod_gaus(tmin, tmax, tstep, tau, sigma, smearing_sigmas=3,  t0=0):\n",
    "    '''Give a generous array for t'''\n",
    "    t = np.arange(tmin, tmax, tstep)\n",
    "    y_unsmeared = exp(t, tau, t0)\n",
    "    \n",
    "    # Maximum number of samples to go left or right\n",
    "    smear_cutoff = int(np.ceil((smearing_sigmas * sigma) / tstep))\n",
    "    y_arr = np.array([gaus(i * tstep, sigma) * shift_samples(y_unsmeared, i) for i in range(-smear_cutoff, smear_cutoff)])\n",
    "#     for y in y_arr:\n",
    "#         plt.plot(t, y)\n",
    "    y = np.sum(y_arr, axis=0)\n",
    "    y = y / np.sum(y) / tstep \n",
    "    \n",
    "    return y\n",
    "    \n",
    "def exp(t, tau, t0):\n",
    "    return (t >= t0) * np.exp(-(t - t0)/(tau))\n",
    "\n",
    "def gaus(x, sigma):\n",
    "    return np.exp(-0.5 * (x / sigma)**2)\n",
    "\n",
    "def shift_samples(y, nsamples):\n",
    "    '''\n",
    "    Shift samples to the right (negative means left)\n",
    "    '''\n",
    "    if nsamples == 0:\n",
    "        return y\n",
    "    elif nsamples > 0:\n",
    "        return np.concatenate([np.zeros(nsamples), y[:-nsamples]])\n",
    "    elif nsamples < 0:\n",
    "        return np.concatenate([y[ - nsamples:], np.zeros(-nsamples)])\n",
    "\n",
    "def rebin(y, nsamples):\n",
    "    if len(y) % nsamples != 0:\n",
    "        raise ValueError('No es possibile')\n",
    "    nbins = int(len(y) / nsamples)\n",
    "    return np.average(np.reshape(y, (nbins, nsamples)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def single_pe_model(channel):\n",
    "    if channel == 0:\n",
    "        tau, sigma, t0_base = (5.42381418,  0.99909129,  0.60783609)\n",
    "    elif channel == 1:\n",
    "        tau, sigma, t0_base = (5.42609904,  0.99867648,  0.86794807)\n",
    "    y_fine = exp_mod_gaus(tmin = valid_t_range[0], tmax = valid_t_range[1], tau=tau,\n",
    "                          sigma = sigma, tstep = dt_fine, t0 = t0_base)\n",
    "    return y_fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gain_params = []\n",
    "for ch, fn in enumerate(['170323_103732', '170323_104831']):\n",
    "    with open(os.path.join(pickle_dir, '%s_ch%d_function.pickle' % (fn, ch)) , 'rb') as infile:\n",
    "        _norm, _popt, _perr = pickle.load(infile)\n",
    "        gain_params.append(np.concatenate([np.array([_norm]), _popt, _perr]))\n",
    "gain_params = np.array(gain_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def area_sample(n_values, gain_params, channel):\n",
    "    norm, mu, sigma, _, _ = gain_params[channel]\n",
    "    lower, upper = (0., 3.)\n",
    "    X = stats.truncnorm((lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n",
    "    return X.rvs(n_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaus_trunc(x, mu, sigma):\n",
    "    return (x > 0) * np.exp( - (x - mu)**2 / (2 * sigma**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S1 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recombination model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Earlier model (WRONG AND DEPRICATED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import scipy.interpolate\n",
    "\n",
    "# def cdf_inverse(tau, tr, tmax, nsteps = 100):\n",
    "#     t = np.linspace(0, tmax, nsteps)\n",
    "#     return scipy.interpolate.interp1d(cdf_r(t, tau, tr), t, bounds_error=False)\n",
    "\n",
    "# def cdf_r(t, tau, tr):\n",
    "#     lambda_s = 1/tau # lambda scintillation\n",
    "#     lambda_r = 1/tr\n",
    "#     A = lambda_s * lambda_r / (lambda_s - lambda_r)\n",
    "#     return A * ((1/lambda_s) * (np.exp(- lambda_s * t) -1) - (1/lambda_r) * (np.exp(- lambda_r * t) -1))\n",
    "\n",
    "# def simulate_recombination_times(nphotons, tau, tr, tmax, nsteps):\n",
    "#     cdf_inv_f = cdf_inverse(tau, tr, tmax, nsteps)\n",
    "#     # Check what the maximum time CDF value is\n",
    "#     cdf_max = cdf_r(tmax, tau, tr)\n",
    "#     if (1 - cdf_max) > 0.05:\n",
    "#         print('Warning: %.2f percent of photons discarted in recombination simulation.' % ((1 - cdf_max) * 100))\n",
    "#     times = cdf_inv_f(np.random.rand(nphotons) * cdf_max)\n",
    "#     return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def Ir(t, tau, tr):\n",
    "#     lambda_s = 1/tau # lambda scintillation\n",
    "#     lambda_r = 1/tr\n",
    "#     n0 = 1\n",
    "#     return n0 * lambda_r * lambda_s / (lambda_s - lambda_r) * (np.exp(- lambda_r * t) - np.exp(- lambda_s * t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# times = simulate_recombination_times(2e5, 3, 15, 200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# t_plot = np.linspace(0, 200, 200)\n",
    "\n",
    "# plt.hist(times, bins=500, range=(0, 200), histtype='step', normed=True, label='Simulated values')\n",
    "# plt.plot(t_plot, Ir(t_plot, 3, 15), label='PDF')\n",
    "# plt.plot(t_plot, Ir(t_plot, 25, 15), label='PDF')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good model (good and not depricated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def n(t, tr):\n",
    "    \"\"\"\n",
    "    Density of ions and electrons supposing hot electron escape prob. of zero and uniform density\n",
    "    \"\"\"\n",
    "    return 1 / (1 + t/tr)\n",
    "\n",
    "def Ir2(t, tau, tr):\n",
    "    '''The intensity of scintillation, AKA the PDF distibution for photons!'''\n",
    "    if isinstance(t, float) or isinstance(t, int):\n",
    "        return np.exp(-t/tau) / tau * integrate.quad(lambda x: n(x, tr)**2 * np.exp(x/tau), 0, t)[0]\n",
    "    else:\n",
    "        return np.array([Ir2(_t, tau, tr) for _t in t])\n",
    "\n",
    "def Ir2_cdf(t, tau, tr):\n",
    "    pdf = Ir2(t, tau, tr)\n",
    "    return np.cumsum(pdf) / sum(pdf)\n",
    "\n",
    "def Ir2_cdf_inv(t, tau, tr):\n",
    "    cdf = Ir2_cdf(t, tau, tr)\n",
    "    return scipy.interpolate.interp1d(cdf, t)\n",
    "\n",
    "def simulate_recombination_times(nphotons, tau, tr, tmax, nsteps):\n",
    "    t = np.linspace(0, tmax, nsteps)\n",
    "    return Ir2_cdf_inv(t, tau, tr)(np.random.rand(nphotons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def n_eta(t, tr, eta):\n",
    "    params = [tr, eta]\n",
    "    y0 = [(1- eta), 1]\n",
    "    # print(eta)\n",
    "    \n",
    "    # Define the differential equations to solve\n",
    "    def f(y, t, params):\n",
    "        n_minus, n_plus = y\n",
    "        tau, eta  = params\n",
    "        alpha = 1/tau\n",
    "        derivs = [- alpha * n_minus * n_plus, - alpha * n_minus * n_plus]\n",
    "        return derivs\n",
    "    \n",
    "    psoln = odeint(f, y0, t, args=(params,))\n",
    "    # Return only the electron number...\n",
    "    return psoln\n",
    "\n",
    "def n_product(t, tr, eta):\n",
    "    psoln = n_eta(t, tr, eta)\n",
    "    n_e = psoln[:, 0]\n",
    "    n_holes = psoln[:, 1]\n",
    "    return 1/ tr * n_e * n_holes\n",
    "\n",
    "\n",
    "def Ir3(t, tau, tr, eta, tmax, nsteps):\n",
    "    t_fine = np.linspace(0, tmax, nsteps)\n",
    "    pdf = np.exp(-t_fine/tau) / tau * np.cumsum(n_product(t_fine, tr, eta) * np.exp(t_fine/tau))\n",
    "    return np.interp(t, t_fine, pdf)\n",
    "\n",
    "def Ir3_cdf(t, tau, tr, eta, tmax, nsteps):\n",
    "    pdf = Ir3(t, tau, tr, eta, tmax, nsteps)\n",
    "    return np.cumsum(pdf) / sum(pdf)\n",
    "\n",
    "def Ir3_cdf_inv(t, tau, tr, eta, tmax, nsteps):\n",
    "    cdf = Ir3_cdf(t, tau, tr, eta, tmax, nsteps)\n",
    "    # 0 in the cdf means at time zero \n",
    "    return scipy.interpolate.interp1d(cdf, t, fill_value=(0, np.inf), bounds_error=False)\n",
    "\n",
    "def simulate_recombination_times2(nphotons, tau, tr, eta, tmax, nsteps):\n",
    "    t = np.linspace(0, tmax, nsteps)\n",
    "    return Ir3_cdf_inv(t, tau, tr, eta, tmax, nsteps)(np.random.rand(nphotons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "def split_s1_groups(x, n_x, areas, channels, **params):\n",
    "    \"\"\"Splits x into groups with uniform (s1_min, s1_max) elements, then return matrix of histograms per group.\n",
    "    Returns: integer array (n_x, n_groups)\n",
    "    n_x: number of possible values in x. Assumed to be from 0 ... n_x - 1\n",
    "    s1_min: minimum S1 number of hits\n",
    "    s1_max: maximum S1 number of hits\n",
    "    \"\"\"\n",
    "    params = get_params(params)\n",
    "    # We want to exhaust the indices x. Simulate a generous amount of S1 sizes\n",
    "    n_s1_est = int(1.5 * 2 * len(x) / (params['s1_min'] + params['s1_max']))\n",
    "    \n",
    "    if params['s1_sample'] == 'data' and 'xams_data' not in globals():\n",
    "        print('Warning: data-derived s1 area distribution not possible, reverting to uniform...')\n",
    "        params['s1_sample'] = 'uniform'\n",
    "    if params['s1_sample'] == 'uniform':\n",
    "        pe_per_s1 = (params['s1_max'] - params['s1_min']) * np.random.random(size=n_s1_est) + params['s1_min']\n",
    "    elif params['s1_sample'] == 'data':\n",
    "        # Take S1 from the data sample\n",
    "        s1s_data = xams_data[params['dset']]['s1']\n",
    "        s1s_data = s1s_data[(s1s_data >= params['s1_min']) & (s1s_data < params['s1_max'])]\n",
    "        pe_per_s1  = np.random.choice(s1s_data, size=n_s1_est)\n",
    "    else:\n",
    "        raise ValueError('Configuration not understood, got this: ', params['s1_sample'])\n",
    "    # These are two arrays for the two channels\n",
    "    # i.e. these will later yield the top and bottom waveform\n",
    "    result0 = np.zeros((n_x, n_s1_est), dtype=float)\n",
    "    result1 = np.zeros((n_x, n_s1_est), dtype=float)\n",
    "    s1_i = _split_s1_groups(x, pe_per_s1, result0, result1, areas, channels)\n",
    "    return result0[:,:s1_i - 1], result1[:,:s1_i - 1]\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def _split_s1_groups(x, pe_per_s1, result0, result1, areas, channels):\n",
    "    # One of these days, I'm going to cut you into little pieces\n",
    "    s1_i = 0\n",
    "    for photon_i, (i, ch) in enumerate(zip(x, channels)):\n",
    "        if pe_per_s1[s1_i] < 0:\n",
    "            s1_i += 1\n",
    "            continue\n",
    "        if ch == 0:\n",
    "            result0[i, s1_i] += areas[photon_i]\n",
    "        if ch == 1:\n",
    "            result1[i, s1_i] += areas[photon_i]\n",
    "        pe_per_s1[s1_i] -= areas[photon_i]\n",
    "    return s1_i \n",
    "\n",
    "# %%timeit\n",
    "# split_s1_groups(np.random.randint(0, 100, size=int(1e6)), 101, 10, 20)\n",
    "\n",
    "def shift(x, n):\n",
    "    \"\"\"Shift the array x n samples to the right, adding zeros to the left.\"\"\"\n",
    "    if n > 0:\n",
    "        return np.pad(x, (n, 0), mode='constant')[:len(x)]\n",
    "    else:\n",
    "        return np.pad(x, (0, -n), mode='constant')[-len(x):]\n",
    "\n",
    "\n",
    "\n",
    "def simulate_s1_pulse(**params):\n",
    "    # n_photons=int(2e5), \n",
    "    \"\"\"Return (wv_matrix, time_matrix, t_shift vector) for simulated S1s, consisting of n_photons in total\n",
    "    \"\"\"\n",
    "    params = get_params(params)\n",
    "    n_photons = params['n_photons']\n",
    "\n",
    "    ##\n",
    "    # Make matrix (n_samples, n_waveforms) of pulse waveforms with various shifts\n",
    "    ##\n",
    "    wv_matrix_list = []\n",
    "    for ch in [0, 1]:\n",
    "        # This is a matrix filled with waveforms, ordered by their SHIFT.\n",
    "        # So, these are all just model waveforms and will be selected later\n",
    "        if params['spe_model'] == 'template':\n",
    "            y = spe_ys[ch]  # This is the CHANNEL\n",
    "            i_noshift = np.searchsorted(spe_t_edges, [0])[0]    # Index corresponding to no shift in the waveform\n",
    "            wv_matrix = np.vstack([shift(y, i - i_noshift) \n",
    "                               for i in range(len(spe_ts))]).T \n",
    "        elif params['spe_model'] == 'expnorm':            \n",
    "            y = single_pe_model(ch)\n",
    "            i_noshift = np.searchsorted(spe_t_edges_fine, [0])[0]    # Index corresponding to no shift in the waveform\n",
    "            wv_matrix = np.vstack([rebin(shift_samples(y, i - i_noshift), int(dt / dt_fine))\n",
    "                               for i in range(len(spe_ts_fine))]).T \n",
    "        else:\n",
    "            raise ValueError('spe model not understood')\n",
    "        wv_matrix_list.append(wv_matrix)\n",
    "    \n",
    "    ##\n",
    "    # Simulate S1 pulse times, convert to index\n",
    "    ##\n",
    "\n",
    "    # Channel selector\n",
    "    n_top = np.random.binomial(n=n_photons, p=params['aft']) # Number of photons happening in top array\n",
    "    # First all the top channels, then all the bottom channels (ch1)\n",
    "    channels = np.concatenate([np.zeros(n_top, dtype=int), np.ones(n_photons - n_top, dtype=int)])\n",
    "    areas = np.concatenate([area_sample(n_top, gain_params, channel=0), \n",
    "                            area_sample(n_photons - n_top, gain_params, channel=1)])\n",
    "    # Shuffle the two lists the exact same way\n",
    "    channels, areas = unison_shuffled_copies(channels, areas)\n",
    "    \n",
    "    # Time is distributed according to exponential distribution\n",
    "    # This is the TRUE time of all the photons generated, assuming time=0  is the time of the interaction\n",
    "    times = np.zeros(n_photons)\n",
    "\n",
    "    if params['s1_model'] == 'two_exp':\n",
    "        n_singlets = np.random.binomial(n=n_photons, p=params['fs']) # We randomly select if the photon came from a \n",
    "                                                                     # singlet or triplet decay\n",
    "        times += np.concatenate([\n",
    "            np.random.exponential(params['t1'], n_singlets),\n",
    "            np.random.exponential(params['t3'], n_photons - n_singlets)\n",
    "        ])\n",
    "    elif params['s1_model'] == 'recombination' or params['s1_model'] == 'recombination2':\n",
    "        n_recombination = np.random.binomial(n=n_photons, p=params['f_r'])\n",
    "        n_recombination_singlets = np.random.binomial(n=n_recombination, p=params['fs_r'])\n",
    "        n_recombination_triplets = n_recombination - n_recombination_singlets\n",
    "        n_direct = n_photons - n_recombination\n",
    "        n_direct_singlets = np.random.binomial(n=n_direct, p=params['fs'])\n",
    "        n_direct_triplets = n_direct - n_direct_singlets\n",
    "        assert (n_recombination_singlets + n_recombination_triplets + n_direct_singlets + n_direct_triplets == n_photons)        \n",
    "        if params['s1_model'] == 'recombination':\n",
    "            times += np.concatenate([\n",
    "                np.random.exponential(params['t1'], n_direct_singlets),\n",
    "                np.random.exponential(params['t3'], n_direct_triplets),\n",
    "                simulate_recombination_times(n_recombination_singlets, params['t1'], params['tr'], 250, 500), \n",
    "                simulate_recombination_times(n_recombination_triplets, params['t3'], params['tr'], 250, 500), \n",
    "            ])\n",
    "        elif params['s1_model'] == 'recombination2':\n",
    "            times += np.concatenate([\n",
    "                np.random.exponential(params['t1'], n_direct_singlets),\n",
    "                np.random.exponential(params['t3'], n_direct_triplets),\n",
    "                simulate_recombination_times2(n_recombination_singlets, params['t1'], params['tr'], params['eta'],\n",
    "                                              250, 1251), \n",
    "                simulate_recombination_times2(n_recombination_triplets, params['t3'], params['tr'], params['eta'],\n",
    "                                              250, 1251), \n",
    "            ])    \n",
    "    else:\n",
    "        raise ValueError('S1 model type not understood, got this: %s' % params['s1_model'])\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Since `times` is now sorted in (singlet, triplet), shuffle them\n",
    "    np.random.shuffle(times)\n",
    "    \n",
    "    # Here we start taking into account detector physics: the transit time spread (simulated as normal dist.)\n",
    "    times += np.random.normal(0, params['tts'], size=n_photons)\n",
    "    \n",
    "    # Find the bin that the photon would be in if it were sampled.\n",
    "    # Now, we delete all the photons that are outside of the bin range and re-match to the bin centers\n",
    "    # (Check the searchsorted documentation)\n",
    "    if params['spe_model'] == 'template':\n",
    "        indices = np.searchsorted(spe_t_edges, times)\n",
    "        indices = indices[~((indices == 0) | (indices == len(spe_t_edges)))] - 1\n",
    "    elif params['spe_model'] == 'expnorm':\n",
    "        indices = np.searchsorted(spe_t_edges_fine, times)\n",
    "        indices = indices[~((indices == 0) | (indices == len(spe_t_edges_fine)))] - 1\n",
    "\n",
    "\n",
    "\n",
    "    # This is the new amount of photons simulated\n",
    "    if len(indices) < n_photons:\n",
    "        # print('Warning: I just threw away %d photons...' % (n_photons - len(indices)))\n",
    "        n_photons = len(indices)\n",
    "    \n",
    "    ##\n",
    "    # Build instruction matrix, simulate waveforms\n",
    "    ##\n",
    "    # So far, we've just been simulating a bunch of photons (very many).\n",
    "    # We are now going to split this into S1s: the split will be made at a random point between s1_min and s1_max.\n",
    "    # `index_matrix` is a matrix split into groups forming S1s. \n",
    "    # We've got two for the two channels    \n",
    "    if params['spe_model'] == 'template':\n",
    "        index_matrix0, index_matrix1 = split_s1_groups(indices, len(spe_t_edges) - 1, areas,channels, **params)\n",
    "    elif params['spe_model'] == 'expnorm':\n",
    "        index_matrix0, index_matrix1 = split_s1_groups(indices, len(spe_t_edges_fine) - 1, areas,channels, **params)\n",
    "\n",
    "    # Now, index_matrix[:, 0] contains a list of number of entries for the shift for each timestamp in bin\n",
    "    n_s1 = index_matrix0.shape[1]\n",
    "    \n",
    "    # Remember that wv_matrix is a matrix of waveforms, each element at position i of which is shifted i samples\n",
    "    s1_waveforms = np.dot(wv_matrix_list[0], index_matrix0) + np.dot(wv_matrix_list[1], index_matrix1)\n",
    "    # return s1_waveforms\n",
    "\n",
    "    ##\n",
    "    # Alignment based on maximum sample, compute average pulse\n",
    "    ##\n",
    "    time_matrix, t_shift = aligned_time_matrix(spe_ts, s1_waveforms)    \n",
    "    return s1_waveforms, time_matrix, t_shift\n",
    "\n",
    "def aligned_time_matrix(ts, wv_matrix, mode = '10p'):\n",
    "    \"\"\"Return time matrix that would align waveforms im wv_matrix\"\"\"\n",
    "    n_s1 = wv_matrix.shape[1]\n",
    "\n",
    "    if mode == 'max':\n",
    "        # Find the position of maximum sample and match its times\n",
    "        t_shift = ts[np.argmax(wv_matrix, axis=0)]\n",
    "    elif mode == '10p':\n",
    "        fraction_reached = np.cumsum(wv_matrix, axis=0) / np.sum(wv_matrix, axis=0)\n",
    "        # Get the sample where 10% is reached by taking the sample closest to the 10% point\n",
    "        # This is as good as you can get without introducing fractional samples (which may be an improvement)\n",
    "        # TODO get interpolation in here\n",
    "        distance_to_10p_point = np.abs(fraction_reached - 0.1)\n",
    "        t_shift = ts[np.argmin(distance_to_10p_point, axis=0)]\n",
    "    \n",
    "    time_matrix = np.repeat(ts, n_s1).reshape(wv_matrix.shape)\n",
    "    time_matrix -= t_shift[np.newaxis,:]\n",
    "    return time_matrix, t_shift\n",
    "\n",
    "def average_pulse(time_matrix, wv_matrix):\n",
    "    \"\"\"Return average pulse, given time and waveform matrices\"\"\"\n",
    "    h, _ = np.histogram(time_matrix, bins=spe_t_edges, weights=wv_matrix)\n",
    "    h /= h.sum()\n",
    "    return h\n",
    "\n",
    "def s1_average_pulse_model(*args, **kwargs):\n",
    "    wv_matrix, time_matrix, _ = simulate_s1_pulse(*args, **kwargs)\n",
    "    return average_pulse(time_matrix, wv_matrix)\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    '''Stack overflow to the rescue'''\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we simulate statistical errors by simulating `n_data_s1s` and then performing bootstrap trials. The conclusion:...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The errors are small but still interesting. We perform the bootstrapping on DATA instead, see later on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def s1_models_resample(*args, n_data_s1s=1000, bootstrap_trials=10, **kwargs):\n",
    "    \"\"\"Return bootstrap_trials waveform templates from sampling n_data_s1s s1s\"\"\"\n",
    "    wv_matrix, time_matrix, _ = simulate_s1_pulse(*args, **kwargs)\n",
    "    n_s1s = wv_matrix.shape[1]\n",
    "    \n",
    "    waveform_templates = np.zeros((len(spe_ts), bootstrap_trials))\n",
    "\n",
    "    for i in range(bootstrap_trials):\n",
    "        new_indices = np.random.randint(n_s1s, size=n_data_s1s)\n",
    "\n",
    "        waveform_templates[:, i] = average_pulse(time_matrix[:, new_indices], \n",
    "                                                 wv_matrix[:, new_indices])\n",
    "    \n",
    "    return waveform_templates\n",
    "\n",
    "def sigmas_plot(x, q, color='b', **kwargs):\n",
    "    for n_sigma, alpha in [(1,0.5), (2, 0.1)]:\n",
    "        plt.fill_between(x,\n",
    "                         np.percentile(q, 100 * stats.norm.cdf(-n_sigma), axis=1),\n",
    "                         np.percentile(q, 100 * stats.norm.cdf(n_sigma), axis=1),\n",
    "                         alpha=alpha, linewidth=0, color=color, step='mid')\n",
    "    plt.plot(x, \n",
    "             np.percentile(q, 50, axis=1), \n",
    "             color=color, linestyle='-', alpha=0.5, linewidth=1, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systematic errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "def s1_models_error(*args, shifts=None, mode='std', **kwargs):\n",
    "    '''\n",
    "    Compute the error on the S1 waveform given errors on specific parameters.\n",
    "    This will compute the S1 model for parameter +error, +0, and -error.\n",
    "    All combinations of parameters are tried.\n",
    "    `shifts` is a dict containting the allowed shift (+/-) for each model parameter.\n",
    "    `*args` and `**kwargs` will be passed to `s1_average_pulse_model` to compute the base model.\n",
    "    This function can also be used for getting the difference in pulse model for channel 0 and 1.\n",
    "    '''\n",
    "    if kwargs.get('neglect_systematic', default_params['neglect_systematic']):\n",
    "        base_model = s1_average_pulse_model(*args, **kwargs)\n",
    "        return base_model, base_model, base_model\n",
    "    \n",
    "    \n",
    "    if shifts is None:\n",
    "        # Default uncertainty: in pulse model and in TTS\n",
    "        shifts = dict(tts=0.5, aft=0.5)\n",
    "    \n",
    "    # Allow specifying a single +- amplitude of variation\n",
    "    for p, shift_values in shifts.items():\n",
    "        if isinstance(shift_values, (float, int)):\n",
    "            shifts[p] = kwargs.get(p, default_params[p]) + np.array([-1, 0, 1]) * shift_values\n",
    "    \n",
    "\n",
    "    shift_pars = sorted(shifts.keys())\n",
    "    shift_values = [shifts[k] for k in shift_pars]\n",
    "    # shift_value_combs is a list of paramters that will be tried to compute the average pulse.\n",
    "    # Contains all combintations: (+, 0, -) for all the parameters. ((3n)^2 for n number of parameters.)\n",
    "    shift_value_combs = list(itertools.product(*shift_values))\n",
    "    noshift_comb = tuple([(kwargs.get(p, default_params[p])) for p, shift_values in shifts.items()])\n",
    "    noshift_index = int((len(shift_value_combs) -1) /2)\n",
    "    # Check if we have the right index\n",
    "    \n",
    "    for i, comb in enumerate(shift_value_combs):\n",
    "        if np.all([np.isclose(a,b) for a, b in zip(comb, noshift_comb)]):\n",
    "            noshift_index = i\n",
    "        \n",
    "        \n",
    "    # for a, b in zip(noshift_comb, shift_value_combs[noshift_index]):\n",
    "        \n",
    "    \n",
    "    alt_models = []\n",
    "    for vs in shift_value_combs:\n",
    "        kw = dict()\n",
    "        kw.update(kwargs)\n",
    "        for i, p in enumerate(shift_pars):\n",
    "            kw[p] = vs[i]        \n",
    "        alt_models.append(s1_average_pulse_model(*args, **kw))\n",
    "    \n",
    "    \n",
    "    alt_models = np.vstack(alt_models)\n",
    "    base_model = alt_models[noshift_index]\n",
    "    # Hmmm. this seems like an upper estimate of the error, no?\n",
    "    # ask jelle\n",
    "    # return alt_models\n",
    "    if mode == 'extreme':\n",
    "        minus = np.min(alt_models, axis=0)\n",
    "        plus = np.max(alt_models, axis=0)\n",
    "    elif mode == 'std':\n",
    "        sigma_sys = np.std(alt_models, axis=0)\n",
    "        minus = base_model - sigma_sys\n",
    "        plus = base_model + sigma_sys\n",
    "    else:\n",
    "        raise ValueError('Mode %s not known' % mode)\n",
    "    \n",
    "    return minus, base_model, plus\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real data waveforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read the S1 data for three (highfield) datasets: NR, ER and BG_NR. We store it in the form of a dict (keys: er, nr, bg_nr). Each dict item is an array containing the waveforms (per row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xams_data = dict()\n",
    "xams_data['nr'], xams_data['er'], xams_data['bg_nr'] = pickle.load(open(os.path.join(pickle_dir, \n",
    "                                                                                     'highfield_dataframes_new.pickle'),'rb'))\n",
    "xams_data['er_0'] = pickle.load(open(os.path.join(pickle_dir, 'zerofield_dataframes_temp.pickle'), 'rb'))\n",
    "xams_data['nr_l'], xams_data['er_l'] = pickle.load(open(os.path.join(pickle_dir, 'lowfield_dataframes.pickle'), 'rb'))\n",
    "xams_s1s = dict()\n",
    "# Get pulse waveforms to matrix rather than object column\n",
    "for k, d in xams_data.items():\n",
    "    xams_s1s[k] = np.array([x for x in d['s1_pulse']])\n",
    "    del d['s1_pulse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example waveform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now use 0.28 +- 0.12 as uncertainty of the fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment, averaging, bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def real_s1_wv(**params):\n",
    "    \"\"\"Return average S1 waveform, number of S1s it was constructed from\"\"\"\n",
    "    params = get_params(params)\n",
    "    \n",
    "    areas = xams_data[params['dset']]['s1'].values\n",
    "    mask = (params['s1_min'] < areas) & (areas < params['s1_max'])\n",
    "\n",
    "    # Could now derive distribution, I'll just assume uniform for the moment.\n",
    "    # Hist1d(areas[mask],\n",
    "    #        bins=np.linspace(params['s1_min'], params['s1_max'], 100)).plot()\n",
    "\n",
    "    n_data_s1s = mask.sum()\n",
    "    wvs = xams_s1s[params['dset']][mask].T\n",
    "    tmat, _ = aligned_time_matrix(spe_ts, wvs)\n",
    "    real_s1_avg =  average_pulse(tmat, wvs)\n",
    "    \n",
    "    return real_s1_avg, n_data_s1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def real_s1_wv_sigma(bootstrap_trials = 25, **params):\n",
    "    \"\"\"Take data S1s, bootstrap sample, then check what the variance is\"\"\"\n",
    "    params = get_params(params)\n",
    "    \n",
    "    time_matrix, wv_matrix = real_s1_wv_matrix(**params)\n",
    "    n_s1s = wv_matrix.shape[1]\n",
    "    waveform_templates = np.zeros((len(spe_ts), bootstrap_trials))\n",
    "\n",
    "    for i in range(bootstrap_trials):\n",
    "        new_indices = np.random.randint(n_s1s, size=n_s1s)\n",
    "\n",
    "        waveform_templates[:, i] = average_pulse(time_matrix[:, new_indices], \n",
    "                                                 wv_matrix[:, new_indices])\n",
    "        \n",
    "    \n",
    "    return np.std(waveform_templates, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def real_s1_wv_matrix(**params):\n",
    "    \"\"\"Return the aligned time matrix and waveform matrix.\"\"\"\n",
    "    params = get_params(params)\n",
    "    \n",
    "    areas = xams_data[params['dset']]['s1'].values\n",
    "    mask = (params['s1_min'] < areas) & (areas < params['s1_max'])\n",
    "\n",
    "    # Could now derive distribution, I'll just assume uniform for the moment.\n",
    "    # Hist1d(areas[mask],\n",
    "    #        bins=np.linspace(params['s1_min'], params['s1_max'], 100)).plot()\n",
    "\n",
    "    n_data_s1s = mask.sum()\n",
    "    wvs = xams_s1s[params['dset']][mask].T\n",
    "    tmat, _ = aligned_time_matrix(spe_ts, wvs)\n",
    "        \n",
    "    return tmat, wvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-data comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigma and residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def residuals(ydata, minus, base, plus, **params):\n",
    "    params = get_params(params)\n",
    "    sigma = get_sigma(minus, base, plus, **params)\n",
    "    if 0. in sigma:\n",
    "        zero_positions = np.where(sigma == 0)\n",
    "        print('Warning: found zero in error array at positions: ', zero_positions)\n",
    "        print('Replacing with infinite error instead...')\n",
    "        for pos in zero_positions:\n",
    "            sigma[pos] = np.inf\n",
    "    return (ydata - base) / sigma\n",
    "\n",
    "def get_sigma(minus, base, plus, **params):\n",
    "    params = get_params(params)\n",
    "    if (np.any(minus > base) | np.any(base > plus)):\n",
    "        raise ValueError('Screw this, negative errors should not be there!')\n",
    "    sigma_syst = np.abs(plus - minus)/2 + params['error_offset'] + params['error_pct'] * np.abs(base)\n",
    "    if params['neglect_statistical']:\n",
    "        print('Neglect!')\n",
    "        return sigma_syst\n",
    "    sigma_stat = real_s1_wv_sigma(bootstrap_trials = 25, **params)\n",
    "    sigma = np.sqrt(sigma_syst**2 + sigma_stat**2)\n",
    "    return sigma\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comparison_plot(ydata, minus, base, plus, log=False, **params):\n",
    "    params = get_params(params)\n",
    "    sigmas = get_sigma(minus, base, plus, **params)\n",
    "\n",
    "    # large subplot\n",
    "    ax2 = plt.subplot2grid((3,1), (2,0))\n",
    "    ax1 = plt.subplot2grid((3,1), (0,0), rowspan=2, sharex=ax2)\n",
    "\n",
    "    #f, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
    "    plt.sca(ax1)\n",
    "    # plt.fill_between(spe_ts, minus, plus, alpha=0.5, linewidth=0, step='mid')\n",
    "    plt.fill_between(spe_ts, base - sigmas, base + sigmas,\n",
    "                     alpha=0.5, linewidth=0, step='mid')\n",
    "    plt.plot(spe_ts, base, linestyle='steps-mid', label='Model')\n",
    "    plt.plot(spe_ts, ydata, marker='.', linestyle='', markersize=3, c='k', label='Observed')\n",
    "\n",
    "    plt.grid(alpha=0.1, linestyle='-', which='both')\n",
    "    plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "    plt.ylabel(\"Fraction of amplitude\")\n",
    "    plt.axhline(0, c='k', alpha=0.5)\n",
    "    leg = plt.legend(loc='upper right', numpoints=1)\n",
    "    leg.get_frame().set_linewidth(0.0)\n",
    "    leg.get_frame().set_alpha(0.5)\n",
    "    if log:\n",
    "        plt.yscale('log')\n",
    "        plt.ylim(1e-5, 1e-1)\n",
    "    else:\n",
    "        plt.ylim(0, None)\n",
    "\n",
    "    #ax1.set_xticklabels([])\n",
    "\n",
    "    # Add residuals\n",
    "    plt.sca(ax2)\n",
    "    plt.subplot2grid((3,1), (2,0), sharex=ax1)\n",
    "    plt.xlim(params['t_min'], params['t_max'])\n",
    "\n",
    "    res = residuals(ydata, minus, base, plus, **params)\n",
    "    \n",
    "    plt.plot(spe_ts, res,\n",
    "             linestyle='', marker='x', c='k', markersize=3)\n",
    "    plt.ylim(-3, 3)\n",
    "    plt.grid(which='both', linestyle='-', alpha=0.1)\n",
    "    plt.axhline(0, c='k', alpha=0.5)\n",
    "\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.xlabel(\"Time since alignment point\")\n",
    "#     plt.text(#plt.xlim()[1] * 0.5, plt.ylim()[1] * 0.6,\n",
    "#              60, 2,\n",
    "#              'Mean abs. res.: %0.3f' % np.abs(res).mean())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.gcf().subplots_adjust(0,0,1,1,0,0)\n",
    "\n",
    "def comparison_plot_2(ydata, minus, base, plus, plot_residual = True, **params):\n",
    "    params = get_params(params)\n",
    "    res = residuals(ydata, minus, base, plus, **params)\n",
    "    sigmas = get_sigma(minus, base, plus, **params)\n",
    "    \n",
    "#     plt.fill_between(spe_ts, minus - params['error_offset'], plus + params['error_offset'],\n",
    "#                      alpha=0.5, linewidth=0, step='mid')\n",
    "    plt.fill_between(spe_ts, base - sigmas, base + sigmas,\n",
    "                     alpha=0.5, linewidth=0, step='mid')\n",
    "    plt.plot(spe_ts, base, linestyle='steps-mid', label='Model')\n",
    "    plt.plot(spe_ts, ydata, marker='.', linestyle='', markersize=3, c='k', label='Observed')\n",
    "    plt.yscale('log')\n",
    "    plt.ylim(2e-5, 1e-1)\n",
    "    plt.ylabel(\"Fraction of amplitude\")\n",
    "    plt.xlabel('Time (ns)')\n",
    "    for _l in (params['t_min'], params['t_max']):\n",
    "        plt.axvline(_l, ls='dotted', color='black')\n",
    "    if plot_residual:\n",
    "        plt.twinx()\n",
    "        plt.plot(spe_ts, np.abs(res), color='red')\n",
    "        plt.ylabel('Residual / error')\n",
    "        plt.ylim(0)\n",
    "    plt.xlim(params['t_min'] - 20, params['t_max'] + 50)\n",
    "    \n",
    "    res = res[(spe_ts >= params['t_min']) & (spe_ts < params['t_max'])]\n",
    "    chi2 = sum(res**2) / len(spe_ts[(spe_ts >= params['t_min']) & (spe_ts < params['t_max'])])\n",
    "    print('chi2 = %f' % chi2)\n",
    "    \n",
    "def plot_model(plot_type = 0, figname = None, plot_residual = True, **params):\n",
    "    params = get_params(params)\n",
    "    print(params)\n",
    "    ydata, _ = real_s1_wv(**params)\n",
    "    minus, base, plus = s1_models_error(**params)\n",
    "    if plot_type == 0 or plot_type == 1:\n",
    "        comparison_plot(ydata, minus, base, plus, **params)\n",
    "        if figname is not None:\n",
    "            plt.savefig('figs/' + figname + '_1.png', bbox_inches = 'tight', dpi = 400)\n",
    "        plt.show()\n",
    "    if plot_type == 0 or plot_type == 2:\n",
    "        comparison_plot_2(ydata, minus, base, plus, plot_residual = plot_residual, **params)\n",
    "        if figname is not None:\n",
    "            plt.savefig('figs/' + figname + '_2.png', bbox_inches = 'tight', dpi = 400)\n",
    "\n",
    "        plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residuals function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gof(verbose=True, mode = 'chi2_ndf', **params):\n",
    "    '''\n",
    "    Get the value to minimize given the parameters\n",
    "    '''\n",
    "    params = get_params(params)\n",
    "    # Do not allow unphysical values\n",
    "    if params['t1'] < 0 or params['t3'] < 0 or not (0 <= params['fs'] <= 1):\n",
    "        result = float('inf')\n",
    "    else:\n",
    "        ydata, _ = real_s1_wv(**params)\n",
    "        minus, base, plus = s1_models_error(**params)\n",
    "        res = residuals(ydata, minus, base, plus, **params)\n",
    "        assert len(res) == len(spe_ts)\n",
    "        res = res[(spe_ts >= params['t_min']) & (spe_ts < params['t_max'])]\n",
    "        if mode == 'mean':\n",
    "            result = np.abs(res).mean()\n",
    "        elif mode == 'median':\n",
    "            result = np.median(np.abs(res))\n",
    "        elif mode == 'chi2':\n",
    "            result = np.sum(res**2)\n",
    "        elif mode == 'chi2_ndf':\n",
    "            result = 1/len(res) * np.sum(res**2)\n",
    "        elif mode == 'res':\n",
    "            result = res\n",
    "        else:\n",
    "            raise ValueError('Mode unknown, got this: %s' % mode)\n",
    "    if verbose and (mode != 'res'):\n",
    "        print('gof={gof}, fs={fs}, t1={t1}, t3={t3}, tts={tts}'.format(gof=result, **params))\n",
    "    return result\n",
    "\n",
    "def gof_repeat(iterations, verbose=True, mode = 'chi2_ndf', metamode = 'median', **params):\n",
    "    params = get_params(params)\n",
    "    if params['t1'] < 0 or params['t3'] < 0 or not (0 <= params['fs'] <= 1):\n",
    "        result = float('inf')\n",
    "    else:\n",
    "        gofs = np.array([gof(verbose=False, mode = mode, **params) for _ in range(iterations)])\n",
    "        if metamode == 'median':\n",
    "            result = np.median(gofs)\n",
    "        elif metamode == 'mean':\n",
    "            result = np.mean(gofs)\n",
    "    if verbose:\n",
    "        print('gof={gof}, fs={fs}, t1={t1}, t3={t3}, tts={tts}'.format(gof=result, **params))\n",
    "    return result    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gof_simultaneous(fs_er, fs_nr, verbose=True, mode='mean', **params):\n",
    "    params = get_params(params)\n",
    "    params_er = deepcopy(params)\n",
    "    params_nr = deepcopy(params)\n",
    "    params_er['dset'] = 'er'\n",
    "    params_nr['dset'] = 'nr'\n",
    "    params_er['fs'] = fs_er\n",
    "    params_nr['fs'] = fs_nr\n",
    "    gof_er = gof(verbose=False, mode=mode, **params_er)\n",
    "    gof_nr = gof(verbose=False, mode=mode, **params_nr)\n",
    "    if verbose:\n",
    "        print('gof_er={gof_er}, gof_nr={gof_nr}, fs_er={fs_er}, fs_nr={fs_nr} t1={t1}, t3={t3}, tts={tts}'.format(\n",
    "            gof_er=gof_er, gof_nr=gof_nr, fs_er = params_er['fs'], fs_nr = params_nr['fs'], **params))    \n",
    "    return gof_er + gof_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()   # start with x's keys and values\n",
    "    z.update(y)    # modifies z with y's keys and values & returns None\n",
    "    return z\n",
    "\n",
    "def minimize_it(param_names, starting_values, **params):\n",
    "    optresult = optimize.minimize(\n",
    "        lambda x: gof(**merge_two_dicts(params, {par : x[i] for i, par in enumerate(param_names)})),\n",
    "        starting_values,\n",
    "        options=dict(maxfev=1000),\n",
    "        method='Powell',\n",
    "    )\n",
    "    return optresult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_combined_model(Linf, plot=False, plot_type = 1, **p):\n",
    "    # Extract the recombination fractions from Linf\n",
    "    if Linf > 143:\n",
    "        return np.inf\n",
    "    dsets_er = ['er_0', 'er_l', 'er']\n",
    "    L = [200, 168, 143] # light yield for 0, 100 and 500 field\n",
    "    frs = [l / Linf -1 for l in L]\n",
    "    gofs = [] \n",
    "    for dset, fr in zip(dsets_er, frs):\n",
    "        p['dset'] = dset\n",
    "        p['f_r'] = fr\n",
    "        if plot:\n",
    "            plot_model(plot_type=plot_type, **p)\n",
    "        gofs.append(gof(**p))\n",
    "    print(gofs)\n",
    "    # Add penalties!\n",
    "    # Linf, t3, fs\n",
    "#     guess_values = [130, 23, 0.25]\n",
    "#     sigmas = [5, 2, 0.5]\n",
    "#     prior_Linf = [1/gaus(Linf - guess_values[0], sigmas[0])]\n",
    "#     prior_thingy = [1/gaus(p[param] - guess_values[i + 1], sigmas[i + 1]) for i, param in enumerate(['t3', 'fs'])]\n",
    "#     prior_thingy = prior_Linf + prior_thingy\n",
    "#     print(prior_thingy)\n",
    "    \n",
    "    return sum(gofs) #  + sum(prior_thingy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
